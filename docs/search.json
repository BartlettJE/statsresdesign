[{"path":"index.html","id":"overview","chapter":"Overview","heading":"Overview","text":"Book Name: Statistics Research Design.Summary: Materials Statistics Research Design course MSc Research Methods Psychological Science programme, University Glasgow School Psychology & Neuroscience.Authors: James Bartlett, Guillaume Rousselet, & Christoph Scheepers.Aim: course covers advanced statistics concepts might need psychological research, normally learn standard curricula. course split three segments lecturer outline core part advanced training. first segment covers general linear model, building simple linear regression mixed effects models (Scheepers). second segment covers statistical fallacies, misconceptions, bootstrapping (Rousselet). third segment covers Bayesian approaches hypothesis testing estimation (Bartlett).Contact: book living document regularly checked updated improvements. issues using book queries, please contact James Bartlett.R Version: book written R version 4.1.3 (2022-03-10).","code":""},{"path":"introduction-to-linear-regression-1.html","id":"introduction-to-linear-regression-1","chapter":"1 Introduction to Linear Regression 1","heading":"1 Introduction to Linear Regression 1","text":"","code":""},{"path":"introduction-to-linear-regression-2.html","id":"introduction-to-linear-regression-2","chapter":"2 Introduction to Linear Regression 2","heading":"2 Introduction to Linear Regression 2","text":"","code":""},{"path":"introduction-to-generalised-linear-models-1.html","id":"introduction-to-generalised-linear-models-1","chapter":"3 Introduction to Generalised Linear Models 1","heading":"3 Introduction to Generalised Linear Models 1","text":"","code":""},{"path":"introduction-to-generalised-linear-models-2.html","id":"introduction-to-generalised-linear-models-2","chapter":"4 Introduction to Generalised Linear Models 2","heading":"4 Introduction to Generalised Linear Models 2","text":"","code":""},{"path":"introduction-to-linear-mixed-effects-models.html","id":"introduction-to-linear-mixed-effects-models","chapter":"5 Introduction to Linear Mixed Effects Models","heading":"5 Introduction to Linear Mixed Effects Models","text":"","code":""},{"path":"introduction-to-percentile-bootstrap.html","id":"introduction-to-percentile-bootstrap","chapter":"6 Introduction to Percentile Bootstrap","heading":"6 Introduction to Percentile Bootstrap","text":"","code":""},{"path":"graphical-representations.html","id":"graphical-representations","chapter":"7 Graphical Representations","heading":"7 Graphical Representations","text":"","code":""},{"path":"myths-and-fallacies.html","id":"myths-and-fallacies","chapter":"8 Myths and Fallacies","heading":"8 Myths and Fallacies","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"introduction-to-bayesian-hypothesis-testing","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9 Introduction to Bayesian Hypothesis Testing","text":"chapter, exploring can perform hypothesis testing Bayesian framework. working interactive apps understand logic behind Bayesian statistics Bayes factors, calculate Bayes factors two independent samples two dependent samples using real data. application Bayes factors still mostly relies testing point null hypothesis, end alternative known Region Practical Equivalence (ROPE). , try reject parameter values inside boundaries smallest effect size interest.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"learning-objectives","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.1 Learning objectives","text":"Understand logic behind Bayesian inference using sweet example Shiny app.Understand logic behind Bayesian inference using sweet example Shiny app.Use online visualisation explore impacts Bayes factors.Use online visualisation explore impacts Bayes factors.Calculate Bayes factors two independent samples.Calculate Bayes factors two independent samples.Calculate Bayes factors two dependent samples.Calculate Bayes factors two dependent samples.Define Region Practical Equivalence (ROPE) alternative null hypothesis testing.Define Region Practical Equivalence (ROPE) alternative null hypothesis testing.follow along chapter try code , please download data files using zip file.Credit sourcing three data sets goes Open Stats LabOpen Stats Lab creator Dr. Kevin McIntyre. project provides great resource teaching exercises using open data.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"bayes-logic","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.2 The Logic Behind Bayesian Inference","text":"demonstrate logic behind Bayesian inference, play around shiny app Wagenmakers (2015). text walks app provides exercises explore , use explore defining prior distribution seeing posterior updates data.example based estimating proportion yellow candies bag different coloured candies. see yellow candy, logged 1. see non-yellow candy, logged 0. want know proportion candies yellow.handy demonstration logic behind Bayesian inference simplest application. Behind scenes, calculate values directly distributions simple one parameter. later examples lesson 10, focus complicated models require sampling posterior.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"step-1---pick-your-prior","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.2.1 Step 1 - Pick your prior","text":"First, define prior expectations proportion yellow candies. dichotomous outcome like (yellow yellow), can model prior beta distribution. two parameters set: b.Explore changing parameters impact distribution, observations orient :Setting 1 create flat prior: proportion possible.Setting 1 create flat prior: proportion possible.Using number centers distribution 0.5, increasing numbers showing greater certainty (higher peak).Using number centers distribution 0.5, increasing numbers showing greater certainty (higher peak).parameter < b, proportions less 0.5 likely.parameter < b, proportions less 0.5 likely.parameter b > , proportions higher 0.5 likely.parameter b > , proportions higher 0.5 likely.playing around, proportion yellow candies think likely? certain value accepting data?","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"step-2---update-to-a-posterior","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.2.2 Step 2 - Update-to-a-posterior","text":"Now prior, time collect data update posterior. lecture, play around practical demonstration seeing many candies yellow, set prior entering value b, see data tell us. two boxes entering data: number yellows observe, number non-yellows observe.trying , explore changing prior data see affects posterior distribution. inspiration key observations:Setting uninformative (1,1) weak prior (2, 2) 0.5, posterior dominated data. example, imagine observed 5 yellows 10 non-yellows. posterior peaks around 0.30 plausibly ranges 0.2 0.6. Changing data completely changes posterior show prior little influence. change number yellows non-yellows, posterior updates dramatically.Setting uninformative (1,1) weak prior (2, 2) 0.5, posterior dominated data. example, imagine observed 5 yellows 10 non-yellows. posterior peaks around 0.30 plausibly ranges 0.2 0.6. Changing data completely changes posterior show prior little influence. change number yellows non-yellows, posterior updates dramatically.Now set strong prior (20, 20) 0.5 5 yellows 10 non-yellows. Despite observed data showing proportion 0.33, peak posterior distribution slightly higher 0.4. posterior compromise prior likelihood, stronger prior means need data change beliefs. example, imagine 10 times data 50 yellows 100 non-yellows. Now, greater density 0.3 0.4, show posterior now convinced proportion yellows.Now set strong prior (20, 20) 0.5 5 yellows 10 non-yellows. Despite observed data showing proportion 0.33, peak posterior distribution slightly higher 0.4. posterior compromise prior likelihood, stronger prior means need data change beliefs. example, imagine 10 times data 50 yellows 100 non-yellows. Now, greater density 0.3 0.4, show posterior now convinced proportion yellows.demonstration, note two curves prior posterior, without likelihood. prior posterior come distribution family, known conjugate prior, beta distribution one simplest. simply modelling proportion successes failures (yellows vs non-yellows).section 4 app, can also explore Bayes factors applied scenario, working much shift belief favour alternative hypothesis compared null (, proportion exactly 0.5). point lecture, explored Bayes factors yet, continue .","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Bayes-factors","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.3 The Logic Behind Bayes Factors","text":"demonstrate logic behind Bayes factors, play around interactive app Magnusson. Building section 1, visualisation shows Bayesian two-sample t-test, demonstrating complicated application compared beta distribution proportions. visualisation shows Bayesian estimation posterior distribution 95% Highest Density Interval (HDI), Bayes factors null hypothesis centered 0. use visualisation reinforce learnt earlier extend understanding logic behind Bayes factors.three settings visualisation, :Observed effect - Expressed Cohen's d, represents standardised mean difference two groups. can set larger effects (positive negative) assume null hypothesis true (d = 0).Observed effect - Expressed Cohen's d, represents standardised mean difference two groups. can set larger effects (positive negative) assume null hypothesis true (d = 0).Sample size - can increase sample size 1 1000, steps 1 100.Sample size - can increase sample size 1 1000, steps 1 100.SD prior - prior always set 0 testing null hypothesis, can specify strong prior . Decreasing SD means confident effect 0. Increasing SD means less certain prior.SD prior - prior always set 0 testing null hypothesis, can specify strong prior . Decreasing SD means confident effect 0. Increasing SD means less certain prior.visualisation set test null hypothesis difference two groups, remember Bayes factors allow test two hypotheses. Bayes factor represented difference two dots, curves represent likelihood 0 prior posterior distributions. Bayes factor ratio two values posterior odds much belief shift favour experimental hypothesis compared null hypothesis.Keep eye p-value 95% Confidence Interval (CI) see inferences similiar different statistical philosophy.reinforce lessons section 1 emphasis now Bayes factors, key observations:less informative prior (higher SD), posterior dominated likelihood show posterior overwhelmed data. example, set SD 2, prior peaks 0 distribution flat accepts reasonable effect. move observed effect anywhere along scale, likelihood posterior almost completely overlap reach d = ±2.less informative prior (higher SD), posterior dominated likelihood show posterior overwhelmed data. example, set SD 2, prior peaks 0 distribution flat accepts reasonable effect. move observed effect anywhere along scale, likelihood posterior almost completely overlap reach d = ±2.stronger prior (lower SD), posterior represents compromise prior likelihood. change SD 0.5 observed effect 1, posterior closer intermediary. may observed data, prior belief null effect strong enough requires data convinced otherwise.stronger prior (lower SD), posterior represents compromise prior likelihood. change SD 0.5 observed effect 1, posterior closer intermediary. may observed data, prior belief null effect strong enough requires data convinced otherwise.participants / data, less uncertainty likelihood. Keeping inputs point 2, 10 participants, likelihood peaks d = 1, easily spans 0 2. increase sample size towards 1000, uncertainty around likelihood lower. data also overwhelms prior, although relatively strong prior null effect, 50 participants, likelihood posterior mostly overlap.participants / data, less uncertainty likelihood. Keeping inputs point 2, 10 participants, likelihood peaks d = 1, easily spans 0 2. increase sample size towards 1000, uncertainty around likelihood lower. data also overwhelms prior, although relatively strong prior null effect, 50 participants, likelihood posterior mostly overlap.Focusing Bayes factor supporting experimental hypothesis, effect, evidence favour experimental hypothesis increases observed effect increases sample size increases. dissimilar frequentist statistical power, Bayesian statistics, optional stopping can less problem (Rouder, 2014, see Schönbrodt et al. (2017) considerations must make). , enough data shift beliefs towards either hypothesis, can collect data update beliefs.Focusing Bayes factor supporting experimental hypothesis, effect, evidence favour experimental hypothesis increases observed effect increases sample size increases. dissimilar frequentist statistical power, Bayesian statistics, optional stopping can less problem (Rouder, 2014, see Schönbrodt et al. (2017) considerations must make). , enough data shift beliefs towards either hypothesis, can collect data update beliefs.set observed effect 0, p-value 1 suggest reject null, remember support null. Bayes factors, can support null see observed effect = 0, sample size = 50, SD prior = 0.5, data 2.60 times likely null experimental hypothesis. , shift belief favour null, convincing. can obtain higher Bayes factor support null increasing sample size increasing SD prior. last part might sound little odd first, prior strong favour null (small SD), beliefs need shift light data.set observed effect 0, p-value 1 suggest reject null, remember support null. Bayes factors, can support null see observed effect = 0, sample size = 50, SD prior = 0.5, data 2.60 times likely null experimental hypothesis. , shift belief favour null, convincing. can obtain higher Bayes factor support null increasing sample size increasing SD prior. last part might sound little odd first, prior strong favour null (small SD), beliefs need shift light data.Finally, set weak prior (SD = 2), see frequentist 95% CI Bayesian 95% HDI almost identical. weak uninformative prior, values two intervals usually similar, must interpret differently. Increasing sample size makes intervals smaller changing observed effect shifts around. make stronger prior (SD = 0.5), now 95% HDI change move observed effect size around. frequentist 95% CI always follow likelihood based observed data. Bayesian 95% HDI represents area posterior, compromise prior likelihood, can smaller stronger prior favour null observed effect 0.Finally, set weak prior (SD = 2), see frequentist 95% CI Bayesian 95% HDI almost identical. weak uninformative prior, values two intervals usually similar, must interpret differently. Increasing sample size makes intervals smaller changing observed effect shifts around. make stronger prior (SD = 0.5), now 95% HDI change move observed effect size around. frequentist 95% CI always follow likelihood based observed data. Bayesian 95% HDI represents area posterior, compromise prior likelihood, can smaller stronger prior favour null observed effect 0.Based observations , try apply understanding questions using Magnusson's interactive app.Assuming moderate effect size d = 0.4 weak prior SD = 0.5, many participants per group need Bayes factor 3 favour alternative hypothesis? Assuming moderate effect size d = 0.4 weak prior SD = 0.5, many participants per group need Bayes factor 3 favour alternative hypothesis? Assuming moderate effect size d = 0.4 50 participants per group, use weaker prior SD = 2, evidence favour alternative hypothesis strongerweakerthe use stronger prior SD = 1.Assuming moderate effect size d = 0.4 50 participants per group, use weaker prior SD = 2, evidence favour alternative hypothesis strongerweakerthe use stronger prior SD = 1.opposite point 5 explanation . Remember Bayes factors represent shift belief one hypothesis compared another. confident null (smaller SD), take evidence shift belief favour alternative hypothesis difference.old rule thumb psychology 20 participants per group provide sufficient statistical power. Assuming moderate effect size d = 0.5 prior SD = 1, difference statistically significant (p = .049). However, looking guidelines provided lecture Wagenmakers et al. (2011), describe evidence favour alternative hypothesis? evidenceAnecdotalSubstantialStrong","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Bayes-independent-samples","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.4 Bayes factors for two independent samples","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"guided-example-bastian-et-al.-2014","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.4.1 Guided example (Bastian et al., 2014)","text":"first time used R chapter, need load packages data task. packages, make sure install first.guided example, reanalyse data Bastian et al. (2014). study wanted investigate whether experiencing pain together can increase levels bonding participants. study trying explain people often say friendships strengthened adversity.Participants randomly allocated two conditions: pain control. Participants pain group experienced mild pain cold pressor task (leaving hand ice cold water) wall squat (sitting wall). control group completed different task involve pain. participants completed scale measure bonded felt participants group. Higher values scale mean greater bonding.independent variable called \"CONDITION\". control group value 0 pain group value 1. wanted find whether participants pain group higher levels bonding fellow participants participants control group. little processing, dependent variable called \"mean_bonding\" mean 7 items related bonding.use Bayesian version t-test, use similar arguments frequentist version stating design formula data frame referring . study, want predict bonding rating group allocated : mean_bonding ~ CONDITION.main new argument rscale sets width prior distribution around alternative hypothesis. T-tests use Cauchy prior similar normal distribution fatter tails define one parameter: r scale. default prior set \"medium\", change depending understanding area research. See function help page different options , medium equivalent value 0.707 scaling Cauchy prior default setting statistics software. two-tailed test, means 50% distribution covers values ± 0.707. can enter numeric value precise scaling word presets like \"medium\", \"wide\", \"ultrawide\" depending weak want prior .worry warning, just previous issues using tibbles BayesFactor package. Now package converts tibbles normal R data frames thing.medium prior, Bayes factor 1.45 (\\(BF\\)\\(_1\\)\\(_0\\) = 1.45), suggesting experimental hypothesis 1.45 times likely point null hypothesis. guidelines Wagenmakers et al. (2011), quite weak anecdotal evidence.authors pretty convinced pain group score higher bonding rating control group, lets see happens one-tailed test see done. need define nullInterval argument state consider negative effects.Make sure check order groups check direction expect results go . expect group smaller group B, code negative effects. expect group bigger group B, code positive effects. common mistake defining wrong direction know order groups coded.one-tailed test, now two tests. row one, test want compare experimental hypothesis (negative effects) point null. row two, opposite complement experimental hypothesis, effect negative. Even one-tailed test, evidence favour experimental hypothesis compared null anecdotal best (\\(BF\\)\\(_1\\)\\(_0\\) = 2.79).wanted test null compared experimental hypothesis, can simply take reciprocal object, demonstrated two-tailed object.object, already know anecdotal evidence favour experimental hypothesis, just telling us null less likely experimental hypothesis (\\(BF\\)\\(_0\\)\\(_1\\) = 0.69). come handy specifically want test null though.purposes rest demonstration, stick original object two-tailed test see can interpret inconclusive results. original study, pain group scored significantly higher control group, p-value .048, hardly convincing evidence. Bayes factors, least can see ideally need data make decision.spend time process week/chapter 10, Bayes factor normally enough. also want estimate effect size precision around . Within BayesFactor package, function sample posterior distribution using MCMC sampling. need pass t-test object posterior function, include number iterations want. use 10,000 . Depending computer, may take seconds.use one-tailed test, must index first object (e.g., Bastian_ttest[1]) one-tailed test includes two lines: 1) directional alternative state null 2) complement alternative null.samples, can use base plot function see trace plots (chapter 10) density plot posterior distributions several parameters.second fourth plots mainly interested t-test. know kind evidence different hypotheses, typically want know effect size . BayesFactor package, get mean difference groups (unhelpfully named beta) effect size Delta, kind like Cohen's d. calculated dividing t statistic square root sample size, type standardised mean difference. One main complaints BayesFactor package explaining outputs mean explanation find old blog post clear overview documentation.plot provides posterior distribution different statistics based sampling 10,000 times. beta, can see peak distribution around -0.5, spanning 0 -1. delta, can see peak distribution around -0.5, spans 0 -1 .fine-tuned description posterior distribution, can use handy functions bayestestR package. use much chapter 10 great plotting functions, functions work BayesFactor objects. get point estimates parameter, can use point_estimate function:best guess (median posterior) mean difference groups -0.49 delta -0.47 favour pain group.just want point estimate though, also want credible interval around . , hdi function., 95% posterior distribution mean difference -1.04 0.04, delta -0.99 0.04. values cross 0, confident findings ideally need collect data, consistent Bayes Factor results.Finally, instead separate functions, handy wrapper median, 95% credible interval, ROPE (later).bunch tests tricks covered , check Bayesfactor package page online series vignettes.","code":"\nlibrary(BayesFactor)\nlibrary(bayestestR)\nlibrary(tidyverse)\nBastian_data <- read_csv(\"data/Bastian.csv\")\n\n# Relabel condition to be more intuitive which group is which \nBastian_data$CONDITION <- factor(Bastian_data$CONDITION, \n                                   levels = c(0, 1), \n                                   labels = c(\"Control\", \"Pain\"))\n\n# We also need to get our DV from the mean of 7 items\nBastian_data <- Bastian_data %>% \n  pivot_longer(names_to = \"item\", # var for item names\n               values_to = \"score\", # var for item scores\n               cols = group101:group107) %>% # Range of columns for group bonding items\n  group_by(across(.cols = c(-item, -score))) %>% # Group by everything but ignore item and score\n  summarise(mean_bonding = mean(score)) %>% # Summarise by creating a subscale name and specify sum or mean\n  ungroup() # Always ungroup\nBastian_ttest <- ttestBF(formula = mean_bonding ~ CONDITION,\n                        data = Bastian_data,\n                        rscale = \"medium\", \n                        paired = FALSE)## Warning: data coerced from tibble to data frame\nBastian_ttest## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 : 1.445956 ±0.01%\n## \n## Against denominator:\n##   Null, mu1-mu2 = 0 \n## ---\n## Bayes factor type: BFindepSample, JZS\nBastian_onetail <- ttestBF(formula = mean_bonding ~ CONDITION,\n                        data = Bastian_data,\n                        rscale = \"medium\", \n                        paired = FALSE,\n                        nullInterval = c(-Inf, 0)) # negative only as we expect control < pain## Warning: data coerced from tibble to data frame\nBastian_onetail## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 -Inf<d<0    : 2.790031  ±0%\n## [2] Alt., r=0.707 !(-Inf<d<0) : 0.1018811 ±0.02%\n## \n## Against denominator:\n##   Null, mu1-mu2 = 0 \n## ---\n## Bayes factor type: BFindepSample, JZS\n1 / Bastian_ttest## Bayes factor analysis\n## --------------\n## [1] Null, mu1-mu2=0 : 0.6915839 ±0.01%\n## \n## Against denominator:\n##   Alternative, r = 0.707106781186548, mu =/= 0 \n## ---\n## Bayes factor type: BFindepSample, JZS\nBastian_samples <- posterior(Bastian_ttest,\n                            iterations = 1e5) # 10,000 in math notation\nplot(Bastian_samples)\npoint_estimate(Bastian_samples)\nhdi(Bastian_samples)\ndescribe_posterior(Bastian_samples)"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Schroeder-activity","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.4.2 Independent activity (Schroeder & Epley, 2015)","text":"independent activity, use data Schroeder Epley (2015). aim study investigate whether delivering short speech potential employer effective landing job writing speech employer reading . Thirty-nine professional recruiters randomly assigned receive job application speech either transcript read, audio recording applicant reading speech.recruiters rated applicants perceived intellect, impression applicant, whether recommend hiring candidate. ratings originally Likert scale ranging 0 (low intellect, impression etc.) 10 (high impression, recommendation etc.), final value representing mean across several items.example, focus hire rating (variable \"Hire_Rating\" see whether audio condition lead higher ratings transcript condition (variable \"CONDITION\")., apply learnt first guided example new independent task complete questions check understanding. Since expect higher ratings audio transcript, use one-tailed test. Remember sample posterior, can also get estimates effect sizes.can check attempt solutions bottom page.Rounding two decimals, Bayes Factor favour alternative hypothesis? Rounding two decimals, Bayes Factor favour alternative hypothesis? Looking guidelines Wagenmakers et al. (2015), describe evidence favour alternative hypothesis? NoAnecdotalSubstantialStrongLooking guidelines Wagenmakers et al. (2015), describe evidence favour alternative hypothesis? NoAnecdotalSubstantialStrongRounding two decimals, absolute (ignoring sign) mean difference (beta) favour audio condition? Rounding two decimals, absolute (ignoring sign) mean difference (beta) favour audio condition? Looking 95% credible interval, can rule effect 0 given data model? YesNoLooking 95% credible interval, can rule effect 0 given data model? YesNo","code":"\nSchroeder_data <- read_csv(\"data/Schroeder_hiring.csv\")\n\n# Relabel condition to be more intuitive which group is which \nSchroeder_data$CONDITION <- factor(Schroeder_data$CONDITION, \n                                   levels = c(0, 1), \n                                   labels = c(\"Transcript\", \"Audio\"))\nSchroeder_ttest <- NULL"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Bayes-dependent-samples","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.5 Bayes factors for two dependent samples","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"guided-example-mehr-et-al.-2016","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.5.1 Guided example (Mehr et al., 2016)","text":"paired samples t-test, process identical independent samples t-test apart defining variables. , demonstrate full example like less commentary, independent data frame test understanding.next study going look Mehr et al. (2016). interested whether singing infants conveyed important information social affiliation. Infants become familiar melodies repeated specific culture. authors interested whether novel person (someone never seen ) signal child member social group attract attention singing familiar song .Mehr et al. (2016) invited 32 infants parents participate repeated measures experiment. First, parents asked repeatedly sing previously unfamiliar song infants two weeks. returned lab, measured baseline gaze (looking) infants towards two unfamiliar people screen just silently smiling . measured proportion time looking individual later sing familiar song (0.5 indicate half time spent looking familiar singer. Values closer one indicate looking longer). two silent people screen took turns sing lullaby. One people sung song infant’s parents told sing previous two weeks, one sang song lyrics rhythm, different melody. Mehr et al. (2016) repeated gaze procedure two people start experiment provide second measure gaze proportion looking familiar singer.interested whether infants increased proportion time spent looking singer sang familiar song sang, comparison sang infants. one dependent variable (gaze proportion) one within-subjects independent variable (baseline vs test). want know whether gaze proportion higher test (\"Test_Proportion_Gaze_to_Singer\") baseline (\"Baseline_Proportion_Gaze_to_Singer\").Like Bastian et al. (2014), just anecdotal evidence favour experimental hypothesis null (\\(BF\\)\\(_1\\)\\(0\\) = 2.30).Mehr et al. (2016) expected gaze proportion higher test, try defining one-tailed test see kind evidence favour alternative hypothesis., know anecdotal evidence favour experimental hypothesis, also want effect size 95% credible interval. , can sample posterior, plot , get estimates.Just note plot fewer panels paired samples approach simplifies things. Mu mean difference first panel delta standardised effect third panel. dependent variable like gaze proportion, unstandardised effect size informative comparable across studies, also useful report standardised effect sizes future power analyses etc.finally wrapper function median posterior distribution 95% credible interval.can see median posterior estimate mean difference -.07 95% credible interval ranging -.13 -.01. dependent variable measured proportion gaze time, infants looked familiar singer 7% (1-13% 95% credible interval) longer test baseline. means can exclude 0 likely effects, still anecdotal evidence favour experimental hypothesis compared null.","code":"\nMehr_data <- read_csv(\"data/Mehr_voice.csv\") %>% \n  select(Baseline = Baseline_Proportion_Gaze_to_Singer, # Shorten super long names\n         Test = Test_Proportion_Gaze_to_Singer)\n\nMehr_ttest <- ttestBF(x = Mehr_data$Baseline,\n                      y = Mehr_data$Test,\n                      paired = TRUE, \n                      rscale = \"medium\")\n\nMehr_ttest## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 : 2.296479 ±0%\n## \n## Against denominator:\n##   Null, mu = 0 \n## ---\n## Bayes factor type: BFoneSample, JZS\nMehr_samples <- posterior(Mehr_ttest,\n                          iterations = 1e5)\n# Subset first plot for mean to display correctly\nplot(Mehr_samples[, 1],\n     main = \"Posterior for mu\")\n# Subset third plot for delta to display correctly\nplot(Mehr_samples[, 3],\n     main = \"Posterior for delta\")\ndescribe_posterior(Mehr_samples)"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Zwaan-activity","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.5.2 Independent activity (Zwaan et al., 2020)","text":"final independent activity, data Zwaan et al. (2020) wanted see replicable experiments cognitive psychology . exercise, explore flanker task.short, two conditions: congruent incongruent. congruent trials, five symbols like arrows participants must identify central symbol keyboard response. incongruent trials, four outer symbols different central symbol. Typically, find participants respond faster congruent trials incongruent trials. dependent variable mean response time milliseconds (ms).want know whether response times faster congruent trials (\"session1_responsecongruent\") incongruent trials (\"session1_incongruent\"). Zwaan et al. measured things like changing stimuli repeating task two sessions, just focus first session example.Perform paired samples t-test comparing response times congruent incongruent trials. questions relate one-tailed test since strong prediction expect faster responses congruent condition compared incongruent condition. Think carefully whether expect positive negative effects depending order enter variables.can check attempt solutions bottom page.Looking guidelines Wagenmakers et al. (2015), describe evidence favour alternative hypothesis? SubstantialStrongVery strongExtremeThe Bayes Factor analysis huge. Unless edit settings, R reports large numbers scientific notation. Bayes Factor favour alternative hypothesis 8.7861e+12 real number 8786100000000. finding established flanker task, testing point null informative, shows extreme evidence looks like. come back ROPE demonstration later.Rounding two decimals, absolute (ignoring sign) mean difference (beta) response time congruent incongruent trials? Rounding two decimals, absolute (ignoring sign) mean difference (beta) response time congruent incongruent trials? Looking 95% credible interval mu, expect absolute mean difference range 30.0638.7847.54ms 30.0638.7847.54ms.Looking 95% credible interval mu, expect absolute mean difference range 30.0638.7847.54ms 30.0638.7847.54ms.Rounding two decimals, absolute standardised mean difference (delta) response time congruent incongruent trials? Rounding two decimals, absolute standardised mean difference (delta) response time congruent incongruent trials? ","code":"\nZwaan_data <- read_csv(\"data/Zwaan_flanker.csv\")\n\nZwaan_ttest <- NULL"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"ROPE","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.6 Equivalence Testing vs ROPE","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"guided-example-for-two-independent-samples-bastian-et-al.-2014","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.6.1 Guided example for two independent samples (Bastian et al., 2014)","text":"sections 9.4 9.5, focused Bayesian approach null hypothesis testing. compared alternative hypothesis null hypothesis wanted know much shift beliefs. However, times comparing point null uninformative. advice applies frequentist statistics can use equivalence testing (see bonus section appendix interested ). setup, set two boundaries representing smallest effect size interest (SESOI) conduct two one-sided test: one comparing sample mean (difference) upper bound one comparing sample mean (difference) lower bound. tests significant, can conclude mean within bounds practically equivalent zero.Bayesian framework, follow similar approach setting upper lower bound interval consider practically theoretically meaningful. known Region Practical Equivalence (ROPE). However, perform two one-sided test, directly compare posterior distribution ROPE interpret much ROPE captures 95% credible interval. creates three decisions (Kruschke & Liddell, 2018) instead comparing experimental hypothesis point null:HDI completely outside ROPE: reject ROPE parameter larger effects consider small practically/theoretically meaningful.HDI completely outside ROPE: reject ROPE parameter larger effects consider small practically/theoretically meaningful.HDI completely within ROPE: accept ROPE parameter smaller effects consider practically/theoretically meaningful.HDI completely within ROPE: accept ROPE parameter smaller effects consider practically/theoretically meaningful.HDI ROPE partially overlap: undecided need data greater precision posterior make decision whether can reject ROPE.HDI ROPE partially overlap: undecided need data greater precision posterior make decision whether can reject ROPE.meaningful chapter 10 turn Bayesian modelling bayestestR package great functions visualising ROPE, unfortunately work BayesFactor objects. return Bastian et al. (2014) data describe_posterior() function. explored complete output earlier, might noticed values relating ROPE, ignored time. reminder, lets see output:information ROPE within bayestestR package, see online vignettes. output, :95% credible interval - need compare ROPE.95% credible interval - need compare ROPE.probability direction (pd) - much posterior distribution positive negative direction?probability direction (pd) - much posterior distribution positive negative direction?Region practical equivalence (ROPE) - interval consider SESOI.Region practical equivalence (ROPE) - interval consider SESOI.% ROPE - much posterior within ROPE?% ROPE - much posterior within ROPE?default, describe_posterior() function sets ROPE region mean plus minus 0.1 * SD response. can set ROPE using rope_range argument. Justifying ROPE probably difficult decision make requires subject knowledge consider smallest effect size interest. lecture, different strategies:understanding applications / mechanisms (e.g., clinically meaningful decrease pain).understanding applications / mechanisms (e.g., clinically meaningful decrease pain).Smallest effects previous research (e.g., lower bound individual study effect sizes lower bound meta-analysis).Smallest effects previous research (e.g., lower bound individual study effect sizes lower bound meta-analysis).Small telescopes (effect size original study 33% power detect).Small telescopes (effect size original study 33% power detect).Bastian et al. (2014), measured bonding 5-point Likert scale, might consider anything less one-point difference small practically meaningful.Note changing ROPE range changes values every parameter, need think parameter interested justifiable ROPE . example, focus mean difference groups (beta). Using ROPE plus minus 1, 99.26% 95% HDI within ROPE. close, falls third decision need data make decision. lower bound HDI -1.03, extends just outside ROPE region.Compared standard Bayes factor weak evidence favour alternative hypothesis compared point null, using ROPE approach means also inconclusive decision, effect size almost small practically meaningful.","code":"\n# rerun the code from section 9.4.1 if you do not have this object saved\ndescribe_posterior(Bastian_samples)\ndescribe_posterior(Bastian_samples,\n                   rope_range = c(-1, 1)) # plus or minus one point difference"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"independent-activity-for-two-independent-samples-schroeder-epley-2014","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.6.2 Independent activity for two independent samples (Schroeder & Epley, 2014)","text":"activity, need objects created section 9.4.2 independent activity. Remember based one-tailed t-test expected higher ratings audio group compared transcript group. need samples posterior thing need change arguments use describe_posterior() function.Use describe_posterior() section 9.4.2, time enter values ROPE arguments. original study 10-point scale. choice ROPE depend understanding subject area, measured outcomes 0-10 scale. might higher bar concluding meaningful effect medium people's hire ratings, use ROPE region 2 points. Since used one-tailed test focusing negative effects (transcript < audio), can just focus region -2 0.can check attempt solutions bottom page.Looking 95% credible interval beta, expect absolute mean difference range 0.322.943.114.52 0.322.943.114.52.Looking 95% credible interval beta, expect absolute mean difference range 0.322.943.114.52 0.322.943.114.52.Rounding two decimals, percentage 95% credible interval within ROPE? Rounding two decimals, percentage 95% credible interval within ROPE? appropriate conclusion based ROPE?:\n\nHDI completely outside ROPE: reject ROPE.HDI completely within ROPE: accept ROPE.HDI ROPE partially overlap: undecided need data.\nappropriate conclusion based ROPE?:","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"guided-example-for-two-dependent-samples-mehr-et-al.-2014","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.6.3 Guided example for two dependent samples (Mehr et al., 2014)","text":"Mehr et al. (2014) data, outcome little easier interpret unstandardised effect two -subjects examples. compared infants' proportion gaze duration spent model sang familiar song wanted know whether increase test compared baseline. proportion gaze bound 0 (none time) 1 (time), might consider 5% (0.05) increase decrease theoretically meaningful certain test higher baseline.observed mean difference posterior median -0.07, 95% CI = [-.13, -0.01], 27.50% within ROPE region plus minus 0.05 points. far ruling ROPE, still need data make decision. Hopefully, can see point, many studies inconclusive conclusions analysed Bayesian framework original frequentist statistics.","code":"\ndescribe_posterior(Mehr_samples,\n                   rope_range = c(-0.05, 0.05))"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"independent-activity-for-two-dependent-samples-zwaan-et-al.-2018","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.6.4 Independent activity for two dependent samples (Zwaan et al., 2018)","text":"activity, need objects created section 9.5.2 independent activity. Remember based one-tailed t-test expected faster response times congruent trials incongruent trials. need samples posterior thing need change arguments use describe_posterior() function.Use describe_posterior() section 9.5.2, time enter values ROPE arguments. Set ROPE -10-0ms (0-10 depending order entered variables) smaller effects closer sampling error can expect response time experiments held online (Reimers & Stewart, 2015).can check attempt solutions bottom page.Looking 95% credible interval mu, expect absolute mean difference range 30.0631.4838.7847.54 30.0631.4838.7847.54.Looking 95% credible interval mu, expect absolute mean difference range 30.0631.4838.7847.54 30.0631.4838.7847.54.percentage 95% credible interval within ROPE? percentage 95% credible interval within ROPE? appropriate conclusion based ROPE?:\n\nHDI completely outside ROPE: reject ROPE.HDI completely within ROPE: accept ROPE.HDI ROPE partially overlap: undecided need data.\nappropriate conclusion based ROPE?:","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"summary","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.7 Summary","text":"chapter, learnt hypothesis testing using Bayesian framework. first two activities explored logic Bayesian statistics make inferences can used test hypotheses expressed Bayes factor. learnt perform Bayes factors applied simplest cases two independent samples two dependent samples. Bayes factors useful way quantifying evidence favour hypotheses compared competing hypothesis. Bayesian statistics can still used mindlessly, hopefully can see provide opportunity move away purely dichotomous thinking. Evidence statistically significant (p < .05) close alpha represents anecdotal evidence.new skill, practice best approach becoming comfortable applying knowledge novel scenario. Hopefully, worked guided examples tested understanding independent activities.learning, recommend following resources relevant chapter:Van Doorn et al. (2021) - Although focuses JASP software, article provides accessible introduction Bayes factors can report findings.Van Doorn et al. (2021) - Although focuses JASP software, article provides accessible introduction Bayes factors can report findings.Kruschke Liddell (2018) - article discusses proposed shift away dichotomous hypothesis testing towards estimation relates Bayesian statistics summarising posterior ROPE procedure.Kruschke Liddell (2018) - article discusses proposed shift away dichotomous hypothesis testing towards estimation relates Bayesian statistics summarising posterior ROPE procedure.Wong et al. (2021) - Although Bayes factors potential help make nuanced inferences, still prone misinterpretations. preprint outlines common errors misconceptions researcher report Bayes factors.Wong et al. (2021) - Although Bayes factors potential help make nuanced inferences, still prone misinterpretations. preprint outlines common errors misconceptions researcher report Bayes factors.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"independent-activity-solutions","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.8 Independent activity solutions","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Schroeder-solution","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.8.1 Schroeder and Epley (2015) Bayes factor","text":"","code":"\nSchroeder_ttest <- ttestBF(formula = Hire_Rating ~ CONDITION,\n        data = Schroeder_data, \n        rscale = \"medium\",\n        nullInterval = c(-Inf, 0)) # Expect negative effects since Transcript < Audio## Warning: data coerced from tibble to data frame\nSchroeder_ttest## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 -Inf<d<0    : 8.205739  ±0%\n## [2] Alt., r=0.707 !(-Inf<d<0) : 0.1020371 ±0%\n## \n## Against denominator:\n##   Null, mu1-mu2 = 0 \n## ---\n## Bayes factor type: BFindepSample, JZS\n# We need to index the first object as a one-tailed test includes two lines: \n# 1. Directional alternative we state against the null\n# 2. Complement of the alternative against the null\n\nSchroeder_samples <- posterior(Schroeder_ttest[1], \n                               iterations = 1e5)\nplot(Schroeder_samples)\ndescribe_posterior(Schroeder_samples)"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Zwaan-solution","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.8.2 Zwaan et al. (2020) Bayes factor","text":"","code":"\nZwaan_ttest <- ttestBF(x = Zwaan_data$session1_responsecongruent,\n                      y = Zwaan_data$session1_incongruent,\n                      paired = TRUE, \n                      rscale = \"medium\",\n                      nullInterval = c(-Inf, 0)) # negative as we expect incongruent to be larger than congruent## t is large; approximation invoked.\n## t is large; approximation invoked.\nZwaan_ttest## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 -Inf<d<0    : 8.786135e+12 ±NA%\n## [2] Alt., r=0.707 !(-Inf<d<0) : 0.00599365   ±NA%\n## \n## Against denominator:\n##   Null, mu = 0 \n## ---\n## Bayes factor type: BFoneSample, JZS\nZwaan_samples <- posterior(Zwaan_ttest[1], # index first item for a one-tailed test\n                          iterations = 1e5)\nplot(Zwaan_samples[, 1],\n     main = \"Posterior for mu\")\nplot(Zwaan_samples[, 3], \n     main = \"Posterior for delta\")\ndescribe_posterior(Zwaan_samples)"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Schroeder-ROPE-solution","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.8.3 Schroeder and Epley (2015) ROPE","text":"","code":"\ndescribe_posterior(Schroeder_samples,\n                   rope_range = c(-2, 0))"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Zwaan-ROPE-solution","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.8.4 Zwaan et al. (2020) ROPE","text":"","code":"\ndescribe_posterior(Zwaan_samples,\n                   rope_range = c(-10, 0))"},{"path":"introduction-to-bayesian-estimation.html","id":"introduction-to-bayesian-estimation","chapter":"10 Introduction to Bayesian Estimation","heading":"10 Introduction to Bayesian Estimation","text":"chapter...","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"learning-objectives-1","chapter":"10 Introduction to Bayesian Estimation","heading":"10.1 Learning objectives","text":"follow along chapter try code , please download data files using zip file.chapter, need packages things cover. separate appendix section (add) prepared help install brms package can sometimes pretty awkward since uses Stan need C++ compiler. really struggling slow computer, brms available R Studio server. See course overview page link never used .","code":"\nlibrary(brms) #fitting Bayesian models\nlibrary(bayestestR) #helper functions for plotting and understanding the models\nlibrary(tidyverse)\nlibrary(see) #helper functions for plotting objects from bayestestR\nlibrary(emmeans) #Handy function for calculating (marginal) effect sizes"},{"path":"introduction-to-bayesian-estimation.html","id":"simple-linear-regression","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2 Simple Linear Regression","text":"","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"guided-example-schroeder-epley-2015","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.1 Guided example (Schroeder & Epley, 2015)","text":"guided activity, use data study Schroeder Epley (2015). used chapter 9 independent activity, explore data set guided example chapter see can refit Bayesian regression model.reminder, aim study investigate whether delivering short speech potential employer effective landing job writing speech employer reading . Thirty-nine professional recruiters randomly assigned receive job application speech either transcript read audio recording reading speech.recruiters rated applicants perceived intellect, impression applicant, whether recommend hiring candidate. ratings originally Likert scale ranging 0 (low intellect, impression etc.) 10 (high impression, recommendation etc.), final value representing mean across several items.example, focus hire rating (variable \"Hire_Rating\") see whether audio condition lead higher ratings transcript condition (variable \"CONDITION\").Remember key steps Bayesian modelling lecture 10 (Heino et al., 2018):Identify data relevant research questionIdentify data relevant research questionDefine descriptive model, whose parameters capture research questionDefine descriptive model, whose parameters capture research questionSpecify prior probability distributions parameters modelSpecify prior probability distributions parameters modelUpdate prior posterior distribution using Bayesian inferenceUpdate prior posterior distribution using Bayesian inferenceCheck model data, identify potential problemsCheck model data, identify potential problems","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"identify-data","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.1.1 1. Identify data","text":"example, data Schroeder Epley, can label conditions intuitive.","code":"\nSchroeder_data <- read_csv(\"data/Schroeder_hiring.csv\")\n\n# Relabel condition to be more intuitive which group is which \nSchroeder_data$CONDITION <- factor(Schroeder_data$CONDITION, \n                                   levels = c(0, 1), \n                                   labels = c(\"Transcript\", \"Audio\"))"},{"path":"introduction-to-bayesian-estimation.html","id":"define-a-descriptive-model","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.1.2 2. Define a descriptive model","text":"next step define descriptive model. chapter 9, used BayesFactor package use ---box tests like t-test, saw lecture Lindeloev (2019) blog post, common statistical models just different expressions linear models. , can express t-test linear model, using \"CONDITION\" single categorical predictor \"Hire_Rating\" outcome. can enter directly brm() function , normally good idea clearly outline component.","code":"\nSchroeder_model1 <- bf(Hire_Rating ~ CONDITION)"},{"path":"introduction-to-bayesian-estimation.html","id":"specify-prior-probability-of-parameters","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.1.3 3. Specify prior probability of parameters","text":"get used brms package, start learn priors need simple cases, now stated model, can see parameters can assigned prior.tells us priors can set default settings . prior, class prior, relevant coefficients, source default now. prior tells default . example, flat uninformative priors coefficients. set priors, can either set priors whole class, specific coefficient. one predictor, one coefficient prior set, makes difference. multiple predictors like later chapter 10, becomes useful.intercept sigma assigned student t distributions priors. pretty wide weak priors.example, use information Schroeder Epley. paper contains four studies data set focuses fourth apply findings professional recruiters. Study 1 preceded used students, can pretend researchers use source priors \"later\" study.Focusing hire rating, found: \"Evaluators heard pitches also reported significantly likely hire candidates (M = 4.34, SD = 2.26) evaluators read exactly pitches (M = 3.06, SD = 3.15), t(156) = 2.49, p = .01, 95% CI difference = [0.22, 2.34], d = 0.40 (see Fig. 1)\"., intercept reference group, can set normally distributed prior around mean 3 SD 3 transcript group. Note rounded values since approximations expect measures manipulations.normally good idea visualise process check numbers enter match expectations. intercept, mean SD 3 look like generating numbers normal distribution:turns quite weak prior since distribution extends 0 (possible scale) way 10 upper limit scale. covers pretty much entire measurement scale peak around 3, represents conservative estimate expect reference group .coefficient, mean difference around 1 (calculated manually subtracting one mean ) 95% CI quite wide 0.22 2.34, can set relatively weak prior expecting normally distributed coefficient mean SD 1:.distribution shows expecting likely value coefficient peak around 1, span -1 (transcript higher audio) around 3 (audio much higher transcript).Now priors, can save new object:Remember important check sensitivity results choice prior. , finished, check stable results uninformative prior, keeping defaults.","code":"\nget_prior(Schroeder_model1, # Model we defined above\n          data = Schroeder_data) # Which data frame are we using? \nset.seed(1928) # set seed to be reproducible\n\nhist(rnorm(100, # how many samples?\n           3, # What mean? \n           3)) # What SD?\nset.seed(1928)\n\nhist(rnorm(100, \n           1, \n           1))\nprior <- set_prior(\"normal(1, 1)\", class = \"b\") + \n  set_prior(\"normal(3, 3)\", class = \"Intercept\")"},{"path":"introduction-to-bayesian-estimation.html","id":"update-the-prior-to-the-posterior","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.1.4 4. Update the prior to the posterior","text":"going longest section going fit brms model explore posterior.process relies sampling using MCMC, important set seed within function reproducibility, semi-random numbers consistent starting point. might take depending computer, get bunch output fitting model sampling MCMC chains.lots data complicated models, fitting process can take long time. means normally good idea save fitted model save time want look quickly. code , argument called file. write character string file directory name want save . Models saved .rds file - R's data file format can save objects . Behind scenes book, must run code every time want update , models see based reading models .rds files first fitted models. save objectives, remember refit change anything like priors, model, data.save model .rds file, can load using read_rds() function readr tidyverse.lot output explain fitting sampling process. lecture references includes longer explanations MCMC sampling works, quick overview, want sample posterior distribution based data model. default brms sample four chains, chain containing 2000 iterations (1000 warm / burn iterations). get warning messages model fit convergence issues, can increase number iterations. becomes important complex models, defaults fine relatively simple models fit chapter. return chains convergence see trace plots later.Now fitted model, can also double check priors set wanted. see source priors set switched default user.Now model, can get model summary like old linear model.top, information model fitting process, like family, data, draws posterior summarising chain iterations.Population-level effects main area interest. posterior probability distribution summary statistics. look whole distribution soon, now, can see median point-estimate intercept 3.01 95% credible interval 2.10 3.96. expect mean reference group , .e., transcript group.median coefficient 1.56 95% credible interval 0.40 2.68. means best guess mean difference / slope increase 1.56 audio group. Note, might get subtly different values output since based semi-random sampling process, main conclusions .convergence issues, Rhat different 1, can suggest problems model fitting process. can also look effective sample size statistics (columns ending ESS), explore lecture.tidier summary parameters, can also use handy describe_posterior() function bayestestR.can use way create ROPE regions effects tells us useful things like probability direction effect.useful comes comparing models building multiple regression models, also specific function get model \\(R^2\\) 95% credible interval. tells proportion variance outcome predictor(s) explain.now, focused point-estimates intervals posterior, main strength Bayesian statistics summarising parameters whole posterior probability distribution, now turn various plotting options.first plot useful seeing posterior parameter trace plots check convergence issues.model, three plots: one intercept, one coefficient/slope, one sigma. left, posterior probability distributions . right, trace plots. default, brms uses four chains - series samples using MCMC - shows chain moves around parameter space. Essentially, want trace plots look like fuzzy caterpillars random series lines. spike deviate massively rest, lines get stuck one area, suggests convergence issues.plots useful initial feel parameter posteriors, great series functions bayestestR package can use , wrap plot() function loading see package. example, can see overlay prior posterior main parameters interest. , p_direction() tells probability direction parameter, .e., much distribution 0? Wrapped plot(), can see prior posterior, posterior divided areas 0.work, must specify priors brms. work package default options coefficients.can see pretty wide prior blue, posterior. Almost posterior distribution zero show pretty confident audio associated higher hire ratings transcript.next useful plot seeing 95% HDI / credible interval. , hdi() show 95% HDI parameters. Wrapped plot(), can visualise HDI compared zero main parameters. HDI excludes zero, can confident positive negative effect, least conditional data model. Remember, difference small world big world models. absolute truth, just credible values conditioned data model.plots informative learning model inferences can learn . However, immediately suitable enter report. Fortunately, created using ggplot, can customise way adding layers additional functions.example, 95% HDI excludes 0, can confident coefficient posterior positive effect, audio group leading higher hire ratings transcript group.Finally, might interested comparing coefficients point-value 0, might stronger level evidence mind, coefficient must exclude range values ROPE process explored chapter 9. example, maybe effects smaller 1 unit difference small practically/theoretically meaningful.Remember potentially difficult decision make, maybe choosing priors. Many areas psychology clear guidelines/expectations smallest effect sizes interest, explain justify approach based understanding topic area.example, sample size 39, pretty strong evidence favour positive effect audio group. 95% HDI excludes zero, set ROPE 1 unit, quite exclude . means wanted confident effect exceeded ROPE, need data. just demonstration purposes, sure original study consider effect 1 practically meaningful, whether just happy non-zero effect.Following chapter 9, saw can also use Bayesian statistics test hypotheses. works modelling approach brms function test hypotheses. must provide fitted model object state hypothesis test. relies character description parameter test value. full explanation, see brms documentation online function. , test coefficient/slope point-null 0.must state character hypothesis requires select parameter. , focus \"CONDITIONAudio\" parameter, .e., slope, must match name model. can state values test , like point-null 0 Bayes factor. Alternatively, can test posterior odds compare masses posterior like CONDITIONAudio > 0.key part output evidence ratio, also estimate 95% credible interval. testing point-null 0, testing null hypothesis alternative non-null effect. value 1, suggests evidence favour alternative compared null. prefer express things 1 easier interpret. can dividing 1 ratio, provide Bayes factor 9.09 .Alternatively, can calculate posterior odds stating regions posterior test. example, used \"CONDITIONAudio > 0\", provide ratio posterior probability positive effects 0 posterior probability negative effects 0. example, posterior odds 209 favour positive effects. Note, posterior 0, can get result Inf (infinity) evidence favour positive effects.","code":"\nSchroeder_fit <- brm(\n  formula = Schroeder_model1, # formula we defined above \n  data = Schroeder_data, # Data frame we're using \n  family = gaussian(), # What distribution family do we want for the likelihood function? Many examples we use in psychology are Gaussian, but check the documentation for options\n  prior = prior, # priors we stated above\n  sample_prior = TRUE, # Setting this to true includes the prior in the object, so we can include it on plots later\n  seed = 1908,\n  file = \"Models/Schroeder_model1\" #Save the model as a .rds file\n)\nSchroeder_fit <- read_rds(\"Models/Schroeder_model1.rds\")\nprior_summary(Schroeder_fit)\nsummary(Schroeder_fit)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: Hire_Rating ~ CONDITION \n##    Data: Schroeder_data (Number of observations: 39) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##                Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept          3.01      0.47     2.10     3.96 1.00     3021     2438\n## CONDITIONAudio     1.56      0.58     0.40     2.68 1.00     3234     2810\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     2.22      0.27     1.77     2.82 1.00     3744     3065\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\ndescribe_posterior(Schroeder_fit)\nbayes_R2(Schroeder_fit)##     Estimate  Est.Error        Q2.5     Q97.5\n## R2 0.1257941 0.07223518 0.007817001 0.2775261\nplot(Schroeder_fit)\nplot(p_direction(Schroeder_fit), \n     priors = TRUE) \nplot(hdi(Schroeder_fit))\nplot(rope(Schroeder_fit, \n          range = c(-1, 1))) # What is the ROPE range for your smallest effects of interest? \nhypothesis(Schroeder_fit, # brms model we fitted earlier\n           hypothesis = \"CONDITIONAudio = 0\") ## Hypothesis Tests for class b:\n##             Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n## 1 (CONDITIONAudio) = 0     1.56      0.58      0.4     2.68       0.11\n##   Post.Prob Star\n## 1       0.1    *\n## ---\n## 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n## '*': For one-sided hypotheses, the posterior probability exceeds 95%;\n## for two-sided hypotheses, the value tested against lies outside the 95%-CI.\n## Posterior probabilities of point hypotheses assume equal prior probabilities.\nhypothesis(Schroeder_fit, # brms model we fitted earlier\n           hypothesis = \"CONDITIONAudio > 0\") ## Hypothesis Tests for class b:\n##             Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio\n## 1 (CONDITIONAudio) > 0     1.56      0.58      0.6      2.5     209.53\n##   Post.Prob Star\n## 1         1    *\n## ---\n## 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n## '*': For one-sided hypotheses, the posterior probability exceeds 95%;\n## for two-sided hypotheses, the value tested against lies outside the 95%-CI.\n## Posterior probabilities of point hypotheses assume equal prior probabilities."},{"path":"introduction-to-bayesian-estimation.html","id":"model-checking","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.1.5 5. Model checking","text":"Finally, model checking procedure. already looked information Rhat trace plots. suggests model fitted OK. also want check model reflects properties data. mean want exactly overfit data, follow similar pattern show model captures features data.Bayesian models generative, means fitted, can use sample values posterior make predictions . One key process called posterior predictive check takes model uses generate new samples. shows conditioned model expects.plot brms function facilitating . thick blue line data outcome. light blue lines 100 samples posterior show model expects outcome.example, OK job capturing pattern data bulk observed data follows generated curves. However, can see data quite flat compared predicted values. expect Gaussian distribution, model happily produce normal curves. model also happily expects values beyond range data scale bound 0 10. hugely common psychological research expect Gaussian distributions ordinal bound data. , model OK job, potentially improve focusing ordinal regression model can factor bounded nature measure.want challenge , recommend working Bürkner Vuorre (2019) applying understanding task. going common theme examples see independent activities psychology articles (included) often use metric models analyse arguably ordinal data.final thing check model sensitive choice prior. justifiable informative prior key strength Bayesian statistics, important check model least two sets priors. example, compare model output default package priors user defined priors used along.code , omitted prior argument, fitting exact model using default package priors.run summary() function , can check intercept predictor coefficients see differ first model fitted. Ideally, provide us similar inferences, similar magnitude direction. never going exactly different priors, want conclusions robust choice prior use.make easier compare, can isolate key information model present side side. can see little difference intercept models. median similar, probability direction values 100%, 95% HDI ranges across similar values. user prior, coefficient little conservative, difference also small , showing results robust choice prior.","code":"\npp_check(Schroeder_fit, \n         ndraws = 100) # How many draws from the posterior? Higher values means more lines\nSchroeder_fit2 <- brm(\n  formula = Schroeder_model1,\n  data = Schroeder_data, \n  family = gaussian(),\n  seed = 1908,\n  file = \"Models/Schroeder_model2\" #Save the model as a .rds file\n)\nsummary(Schroeder_fit2)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: Hire_Rating ~ CONDITION \n##    Data: Schroeder_data (Number of observations: 39) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##                Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept          2.90      0.52     1.89     3.93 1.00     3369     2457\n## CONDITIONAudio     1.82      0.73     0.33     3.24 1.00     3578     2469\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     2.22      0.27     1.77     2.83 1.00     3446     2868\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"introduction-to-bayesian-estimation.html","id":"independent-activity-brandt-et-al.-2014","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.2 Independent activity (Brandt et al., 2014)","text":"independent activity, use data study Brandt et al. (2014). aim Brandt et al. replicate relatively famous social psychology study effect recalling unethical behaviour perception brightness.common language, unethical behaviour considered \"dark\", original authors designed priming experiment participants randomly allocated recall unethical behaviour ethical behaviour past. Participants completed series measures including perception bright testing room . Brandt et al. sceptical wanted replicate study see find similar results.Participants randomly allocated (\"ExpCond\") recall unethical behaviour (n = 49) ethical behaviour (n = 51). key outcome perception bright room (\"WellLitSca\"), 1 (bright ) 7 (bright). research question : recalling unethical behaviour lead people perceive room darker recall ethical behaviour?Use understanding design address research question. follow link Brandt et al. , means standard deviations original study included Table 2. might useful thinking priors, keep mind sensitive conclusions choice prior., apply learnt first guided example new independent activity.","code":"\nBrandt_data <- read_csv(\"data/Brandt_unlit.csv\")\n\n# Recode to dummy coding \nBrandt_data <- Brandt_data %>% \n  dplyr::mutate(ExpCond = dplyr::case_when(ExpCond == 1 ~ 0,\n                             ExpCond == -1 ~ 1))\n\n# Relabel condition to be more intuitive which group is which \n# Ethical is the reference group\nBrandt_data$ExpCond <- factor(Brandt_data$ExpCond, \n                                   levels = c(0, 1), \n                                   labels = c(\"Ethical\", \"Unethical\"))\nBrandt_model1 <- NULL"},{"path":"introduction-to-bayesian-estimation.html","id":"multiple-linear-regression","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3 Multiple Linear Regression","text":"","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"guided-example-heino-et-al.-2018","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3.1 Guided example (Heino et al., 2018)","text":"","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"identify-data-1","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3.1.1 1. Identify data","text":"second guided example covered lecture, explore model included Heino et al. (2018) Bayesian data analysis tutorial. explored feasibility acceptability ”Let’s Move ” intervention increase physical activity 43 older adolescents.randomised participants two groups (\"intervention\") control (0) intervention (1) arms (group sessions motivation self-regulation skills, teacher training). outcome measure autonomous motivation (\"value\") 1-5 scale, higher values meaning greater motivation. measured outcome baseline (0) six weeks (1; \"time\").research question : extent intervention affect autonomous motivation?Part tutorial discusses bigger multilevel model considering different scenarios, demonstration, just averaging scenarios get mean motivation.","code":"\nHeino_data <- read_csv(\"data/Heino-2018.csv\") %>% \n  group_by(ID, intervention, time) %>% \n  summarise(value = mean(value, na.rm = TRUE)) %>% \n  ungroup()"},{"path":"introduction-to-bayesian-estimation.html","id":"define-a-descriptive-model-1","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3.1.2 2. Define a descriptive model","text":"recommend reading article explain process detail. essentially outcome autonomous motivation (\"value\") want look interaction \"intervention\" \"time\". define fixed intercept model 1 + part. also technically multi-level model define random intercept participant ((1 | ID)) ensure recognise time within-subjects.default, R includes fixed intercept (1 + part) model, get results without adding model. However, people often include explicit model formula.","code":"\nHeino_model <- bf(value ~ 1 + time * intervention + (1 | ID))"},{"path":"introduction-to-bayesian-estimation.html","id":"specify-prior-probability-of-parameters-1","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3.1.3 3. Specify prior probability of parameters","text":"Compared simple linear regression, add predictors, number priors can set also increase. output , see can enter prior beta coefficients one specific predictors. also different options setting prior standard deviations sigma.Note, get warning missing data since multi-level model, just fewer observations conditions instead whole case removed.another place recommend reading original article information. discuss choices essentially settle wide weak priors coefficients say small effects likely allow larger effects. two standard deviation classes assigned relatively wide Cauchy priors allow positive values.","code":"\nget_prior(Heino_model, data = Heino_data)## Warning: Rows containing NAs were excluded from the model.\nHeino_priors <- prior(normal(0, 5), class = \"b\") +\n  prior(cauchy(0, 1), class = \"sd\") +\n  prior(cauchy(0, 2), class = \"sigma\")"},{"path":"introduction-to-bayesian-estimation.html","id":"update-prior-to-posterior","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3.1.4 4. Update prior to posterior","text":"going longest section going fit brms model explore posterior.process relies sampling using MCMC, important set seed reproducibility, semi-random numbers consistent starting point. might take depending computer, get bunch output fitting model sampling MCMC chains.Now fitted model, look summary.model summary similar examples simple linear regression section, also new section group-level effects since added random intercept participants.Exploring coefficients, effects pretty small, largest effect 0.10 units. quite bit uncertainty , 95% credible intervals spanning negative positive effects.start, particularly complicated models like , plotting going best friend understanding going .Regardless output look , much going across predictors. data comes feasibility study, sample size pretty small mainly receptive participants intervention.bonus extra, can also use emmeans package calculate marginal effects posterior distribution. important little can learn breaking interaction , might come handy future.provides median value posterior combination time intervention. , can see pretty clearly much going , little difference across estimates 95% credible intervals overlapping.Depending want express marginal means, can also use emmeans object calculate contrasts, expressing effects mean differences posterior group/condition.","code":"\nHeino_fit <- brm(\n  formula = Heino_model,\n  data = Heino_data,\n  prior = Heino_priors,\n  family = gaussian(),\n  seed = 2108,\n  file = \"Models/Heino_model\"\n)\nsummary(Heino_fit)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: value ~ 1 + time * intervention + (1 | ID) \n##    Data: Heino_data (Number of observations: 68) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Group-Level Effects: \n## ~ID (Number of levels: 40) \n##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sd(Intercept)     0.71      0.10     0.53     0.92 1.00      817     1710\n## \n## Population-Level Effects: \n##                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept             3.70      0.20     3.29     4.09 1.00      810     1328\n## time                  0.08      0.14    -0.19     0.37 1.00     2170     2694\n## intervention         -0.08      0.26    -0.59     0.43 1.00      762     1446\n## time:intervention     0.10      0.18    -0.25     0.44 1.00     2203     2552\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     0.33      0.05     0.25     0.44 1.00     1107     1982\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\nplot(Heino_fit)\nplot(p_direction(Heino_fit), \n     priors = TRUE) # plot the priors\nplot(hdi(Heino_fit))\n# Surround with brackets to both save and output\n(Heino_means <- emmeans(Heino_fit, # add the model object  \n        ~ time | intervention)) # We want to separate time by levels of intervention## intervention = 0:\n##  time emmean lower.HPD upper.HPD\n##     0   3.69      3.32      4.11\n##     1   3.78      3.39      4.18\n## \n## intervention = 1:\n##  time emmean lower.HPD upper.HPD\n##     0   3.61      3.27      3.91\n##     1   3.79      3.46      4.12\n## \n## Point estimate displayed: median \n## HPD interval probability: 0.95\ncontrast(Heino_means)## intervention = 0:\n##  contrast estimate lower.HPD upper.HPD\n##  0 effect  -0.0418   -0.1802    0.0957\n##  1 effect   0.0418   -0.0957    0.1802\n## \n## intervention = 1:\n##  contrast estimate lower.HPD upper.HPD\n##  0 effect  -0.0909   -0.1919    0.0216\n##  1 effect   0.0909   -0.0216    0.1919\n## \n## Point estimate displayed: median \n## HPD interval probability: 0.95"},{"path":"introduction-to-bayesian-estimation.html","id":"model-check","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3.1.5 5. Model check","text":"final step, can look posterior predictive check make sure model capturing features data. Compared first guided example, model maps onto data quite well, samples largely following underlying data. still using metric models analyse ultimately ordinal data (despite calculating mean response), expected values go beyond range data (1-5).scroll end Heino et al. article, demonstrate can fit ordinal model data.","code":"\npp_check(Heino_fit,\n         ndraws = 100) # 100 draws from the model"},{"path":"introduction-to-bayesian-estimation.html","id":"independent-activity-coleman-et-al.-2014","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3.2 Independent activity (Coleman et al., 2014)","text":"independent activity, use data study Coleman et al. (2014). Coleman et al. contains two studies investigating religious mystical experiences. One study focused undergraduates second study focused experienced meditators part unique religious group.data set contains range variables used full model paper. going focus small part exercise, feel free explore developing full model used study 1. key variables :\"Age\" - Measured years\"Age\" - Measured years\"Gender\" - 0 = male; 1 = female\"Gender\" - 0 = male; 1 = female\"Week_med\" - Ordinal measure often people meditate per week, higher values meaning often\"Week_med\" - Ordinal measure often people meditate per week, higher values meaning often\"Time_session\" - Ordinal measure long people meditate per session, higher values meaning longer\"Time_session\" - Ordinal measure long people meditate per session, higher values meaning longer\"Absorption_SUM\" - Sum score Modified Tellegen Absorption scale, higher values meaning greater trait levels imaginative engagement\"Absorption_SUM\" - Sum score Modified Tellegen Absorption scale, higher values meaning greater trait levels imaginative engagement\"EQ_SUM\" - Sum score Empathizing Quotient short form, higher values meaning greater theory mind ability\"EQ_SUM\" - Sum score Empathizing Quotient short form, higher values meaning greater theory mind ability\"Mscale_SUM\" - Sum score Hood M-scale, higher values meaning self-reported mystical experiences\"Mscale_SUM\" - Sum score Hood M-scale, higher values meaning self-reported mystical experiencesPrevious studies explored components separately mainly undergraduates, Coleman et al. took opportunity explore unique sample highly committed religious group. final model included seven variables, example, just focus absorption (\"Absorption_SUM\") mentalizing (\"EQ_SUM\") main contributors, variables covariates.research question : absorption (\"Absorption_SUM\") mentalizing (\"EQ_SUM\") affect mystical experiences (\"Mscale_SUM\") outcome? Focus entering two variables individual predictors first, explore interaction.Use understanding design address research question. follow link Coleman et al. , can see results study 2 focused undergraduate students. study presented second, can use example develop understanding measures priors. Think whether weaker stronger priors depending understanding topic, keep mind sensitive conclusions choice prior., apply learnt first guided example new independent task.","code":"\nColeman_data <- read_csv(\"data/Coleman_2019.csv\")\nColeman_model <- NULL"},{"path":"installing-r.html","id":"installing-r","chapter":"A Installing R","heading":"A Installing R","text":"Installing R RStudio usually straightforward. sections explain helpful YouTube video .","code":""},{"path":"installing-r.html","id":"installing-base-r","chapter":"A Installing R","heading":"A.1 Installing Base R","text":"Install base R. Choose download link operating system (Linux, Mac OS X, Windows).Mac, install latest release newest R-x.x.x.pkg link (legacy version older operating system). install R, also install XQuartz able use visualisation packages.installing Windows version, choose \"base\" subdirectory click download link top page. install R, also install RTools; use \"recommended\" version highlighted near top list.using Linux, choose specific operating system follow installation instructions.","code":""},{"path":"installing-r.html","id":"installing-rstudio","chapter":"A Installing R","heading":"A.2 Installing RStudio","text":"Go rstudio.com download RStudio Desktop (Open Source License) version operating system list titled Installers Supported Platforms.","code":""},{"path":"installing-r.html","id":"rstudio-settings","chapter":"A Installing R","heading":"A.3 RStudio Settings","text":"settings fix immediately updating RStudio. Go Global Options... Tools menu (⌘,), General tab, uncheck box says Restore .RData workspace startup. keep things around workspace, things get messy, unexpected things happen. always start clear workspace. also means never want save workspace exit, set Never. thing want save scripts.may also want change appearance code. Different fonts themes can sometimes help visual difficulties dyslexia.\nFigure .1: RStudio General Appearance settings\nmay also want change settings Code tab. Foe example, Lisa prefers two spaces instead tabs code likes able see whitespace characters. matter personal preference.\nFigure .2: RStudio Code settings\n","code":""},{"path":"installing-r.html","id":"installing-latex","chapter":"A Installing R","heading":"A.4 Installing LaTeX","text":"can install LaTeX typesetting system produce PDF reports RStudio. Without additional installation, able produce reports HTML PDF. course require make PDFs. generate PDF reports, additionally need install tinytex (Xie, 2022) run following code:","code":"\ntinytex::install_tinytex()"},{"path":"Frequentist-Equivalence.html","id":"Frequentist-Equivalence","chapter":"B Frequentist Equivalence Testing","heading":"B Frequentist Equivalence Testing","text":"Link Lakens et al. papersLink Lakens et al. papersRepeat examples ROPE show differentRepeat examples ROPE show differentShow plotShow plot","code":""},{"path":"conventions.html","id":"conventions","chapter":"C Conventions","heading":"C Conventions","text":"book use following conventions:Generic code: list(number = 1, letter = \"\")Highlighted code: dplyr::slice_max()File paths: data/sales.csvR Packages: tidyverseBacktick functions: paste()Functions: paste()Strings: \"psyTeachR\"Numbers: 100, 3.14Logical values: TRUE, FALSEGlossary items: ordinalCitations: Wickham (2022)Internal links: Chapter ??External links: R Data ScienceMenu/interface options: New File...","code":""},{"path":"conventions.html","id":"webexercises","chapter":"C Conventions","heading":"C.1 Webexercises","text":"See webexercises details use materials.Type integer: going learn lot: TRUEFALSEWhat p-value?\n\nprobability null hypothesis truethe probability observed (extreme) data, assumption null-hypothesis truethe probability making error conclusion\nfound hidden text!","code":"\nprint(\"You found some hidden code!\")## [1] \"You found some hidden code!\""},{"path":"conventions.html","id":"alert-boxes","chapter":"C Conventions","heading":"C.2 Alert boxes","text":"Informational asides.Notes warn something.Notes things cause serious errors.Try .","code":""},{"path":"conventions.html","id":"code-chunks","chapter":"C Conventions","heading":"C.3 Code Chunks","text":"","code":"\n# code chunks\npaste(\"Applied\", \"Data\", \"Skills\", 1, sep = \" \")## [1] \"Applied Data Skills 1\"```{r setup, message = FALSE}\n# code chunks with visible r headers\nlibrary(tidyverse)```"},{"path":"conventions.html","id":"glossary","chapter":"C Conventions","heading":"C.4 Glossary","text":"","code":""},{"path":"glossary-1.html","id":"glossary-1","chapter":"D Glossary","heading":"D Glossary","text":"can use glossary() function automatically link term psyTeachR glossary make project-specific glossary.create link glossary include tooltip short definition hover term. Use following syntax inline r: glossary(\"word\"). example, common data types integer, double, character.need link definition, using different form word, add display version second argument (display). can also override automatic short definition providing third argument (def). Add argument link = FALSE just want hover definition link psyTeachR glossary.[1] \"Data Types\"can add glossary table end chapter following code. creates table terms used chapter previous glossary_table() function. uses kableExtra(), use code chunk, set results='asis'.want contribute glossary, fork github project, add terms submit pull request, suggest new term issues page.","code":"\nglossary(\"data type\", \n         display = \"Data Types\", \n         def = \"My custom definition of data types\", \n         link = FALSE)```{r, echo=FALSE, results='asis'}\nglossary_table()```"},{"path":"license.html","id":"license","chapter":"License","heading":"License","text":"book licensed Creative Commons Attribution-ShareAlike 4.0 International License (CC--SA 4.0). free share adapt book. must give appropriate credit (DeBruine, 2021), provide link license, indicate changes made. adapt material, must distribute contributions license original.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
