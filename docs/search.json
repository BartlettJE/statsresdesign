[{"path":"index.html","id":"overview","chapter":"Overview","heading":"Overview","text":"Book Name: Statistics Research Design.Summary: Materials Statistics Research Design course MSc Research Methods Psychological Science programme, University Glasgow School Psychology & Neuroscience.Authors: James Bartlett, Guillaume Rousselet, & Christoph Scheepers.Aim: course covers advanced statistics concepts might need psychological research, normally learn standard curricula. course split three segments lecturer outline core part advanced training. first segment covers general linear model, building simple linear regression mixed effects models (Scheepers). second segment covers statistical fallacies, misconceptions, bootstrapping (Rousselet). third segment covers Bayesian approaches hypothesis testing estimation (Bartlett).Contact: book living document regularly checked updated improvements. issues using book queries, please contact James Bartlett.R Version: book written R version 4.1.3 (2022-03-10).","code":""},{"path":"introduction-to-linear-regression-1.html","id":"introduction-to-linear-regression-1","chapter":"1 Introduction to Linear Regression 1","heading":"1 Introduction to Linear Regression 1","text":"Coming soon!","code":""},{"path":"introduction-to-linear-regression-2.html","id":"introduction-to-linear-regression-2","chapter":"2 Introduction to Linear Regression 2","heading":"2 Introduction to Linear Regression 2","text":"Coming soon!","code":""},{"path":"introduction-to-generalised-linear-models-1.html","id":"introduction-to-generalised-linear-models-1","chapter":"3 Introduction to Generalised Linear Models 1","heading":"3 Introduction to Generalised Linear Models 1","text":"Coming soon!","code":""},{"path":"introduction-to-generalised-linear-models-2.html","id":"introduction-to-generalised-linear-models-2","chapter":"4 Introduction to Generalised Linear Models 2","heading":"4 Introduction to Generalised Linear Models 2","text":"Coming soon!","code":""},{"path":"introduction-to-linear-mixed-effects-models.html","id":"introduction-to-linear-mixed-effects-models","chapter":"5 Introduction to Linear Mixed Effects Models","heading":"5 Introduction to Linear Mixed Effects Models","text":"Coming soon!","code":""},{"path":"introduction-to-percentile-bootstrap.html","id":"introduction-to-percentile-bootstrap","chapter":"6 Introduction to Percentile Bootstrap","heading":"6 Introduction to Percentile Bootstrap","text":"Coming soon!","code":""},{"path":"graphical-representations.html","id":"graphical-representations","chapter":"7 Graphical Representations","heading":"7 Graphical Representations","text":"Coming soon!","code":""},{"path":"myths-and-fallacies.html","id":"myths-and-fallacies","chapter":"8 Myths and Fallacies","heading":"8 Myths and Fallacies","text":"Coming soon!","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"introduction-to-bayesian-hypothesis-testing","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9 Introduction to Bayesian Hypothesis Testing","text":"chapter, exploring can perform hypothesis testing Bayesian framework. working interactive apps understand logic behind Bayesian statistics Bayes factors, calculate Bayes factors two independent samples two dependent samples using real data. application Bayes factors still mostly relies testing point null hypothesis, end alternative known Region Practical Equivalence (ROPE). , try reject parameter values inside boundaries smallest effect size interest.always welcome provide feedback resources, book part new suite materials developing. comments, please complete online short anonymous form contact one lecturing team directly.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"learning-objectives","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.1 Learning objectives","text":"end chapter, able :Understand logic behind Bayesian inference using sweet example Shiny app.Understand logic behind Bayesian inference using sweet example Shiny app.Use online visualisation explore impacts Bayes factors.Use online visualisation explore impacts Bayes factors.Calculate Bayes factors two independent samples.Calculate Bayes factors two independent samples.Calculate Bayes factors two dependent samples.Calculate Bayes factors two dependent samples.Define Region Practical Equivalence (ROPE) alternative null hypothesis testing.Define Region Practical Equivalence (ROPE) alternative null hypothesis testing.follow along chapter try code , please download data files using zip file.Credit sourcing three data sets goes Open Stats Lab creator Dr. Kevin McIntyre. project provides great resource teaching exercises using open data.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"bayes-logic","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.2 The Logic Behind Bayesian Inference","text":"demonstrate logic behind Bayesian inference, play around shiny app Wagenmakers (2015). text walks app provides exercises explore , use explore defining prior distribution seeing posterior updates data.example based estimating proportion yellow candies bag different coloured candies. see yellow candy, logged 1. see non-yellow candy, logged 0. want know proportion candies yellow.handy demonstration logic behind Bayesian inference simplest application. Behind scenes, calculate values directly distributions simple one parameter. later examples lesson 10, focus complicated models require sampling posterior.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"step-1---pick-your-prior","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.2.1 Step 1 - Pick your prior","text":"First, define prior expectations proportion yellow candies. dichotomous outcome like (yellow yellow), can model prior beta distribution. two parameters set: b.Explore changing parameters impact distribution, observations orient :Setting 1 create flat prior: proportion possible.Setting 1 create flat prior: proportion possible.Using number centers distribution 0.5, increasing numbers showing greater certainty (higher peak).Using number centers distribution 0.5, increasing numbers showing greater certainty (higher peak).parameter < b, proportions less 0.5 likely.parameter < b, proportions less 0.5 likely.parameter b > , proportions higher 0.5 likely.parameter b > , proportions higher 0.5 likely.playing around, proportion yellow candies think likely? certain value accepting data?","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"step-2---update-to-a-posterior","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.2.2 Step 2 - Update-to-a-posterior","text":"Now prior, time collect data update posterior. lecture, play around practical demonstration seeing many candies yellow, set prior entering value b, see data tell us. two boxes entering data: number yellows observe, number non-yellows observe.trying , explore changing prior data see affects posterior distribution. inspiration key observations:Setting uninformative (1,1) weak prior (2, 2) 0.5, posterior dominated data. example, imagine observed 5 yellows 10 non-yellows. posterior peaks around 0.30 plausibly ranges 0.2 0.6. Changing data completely changes posterior show prior little influence. change number yellows non-yellows, posterior updates dramatically.Setting uninformative (1,1) weak prior (2, 2) 0.5, posterior dominated data. example, imagine observed 5 yellows 10 non-yellows. posterior peaks around 0.30 plausibly ranges 0.2 0.6. Changing data completely changes posterior show prior little influence. change number yellows non-yellows, posterior updates dramatically.Now set strong prior (20, 20) 0.5 5 yellows 10 non-yellows. Despite observed data showing proportion 0.33, peak posterior distribution slightly higher 0.4. posterior compromise prior likelihood, stronger prior means need data change beliefs. example, imagine 10 times data 50 yellows 100 non-yellows. Now, greater density 0.3 0.4, show posterior now convinced proportion yellows.Now set strong prior (20, 20) 0.5 5 yellows 10 non-yellows. Despite observed data showing proportion 0.33, peak posterior distribution slightly higher 0.4. posterior compromise prior likelihood, stronger prior means need data change beliefs. example, imagine 10 times data 50 yellows 100 non-yellows. Now, greater density 0.3 0.4, show posterior now convinced proportion yellows.demonstration, note two curves prior posterior, without likelihood. prior posterior come distribution family, known conjugate prior, beta distribution one simplest. simply modelling proportion successes failures (yellows vs non-yellows).section 4 app, can also explore Bayes factors applied scenario, working much shift belief favour alternative hypothesis compared null (, proportion exactly 0.5). point lecture, explored Bayes factors yet, continue .","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Bayes-factors","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.3 The Logic Behind Bayes Factors","text":"demonstrate logic behind Bayes factors, play around interactive app Magnusson. Building section 1, visualisation shows Bayesian two-sample t-test, demonstrating complicated application compared beta distribution proportions. visualisation shows Bayesian estimation posterior distribution 95% Highest Density Interval (HDI), Bayes factors null hypothesis centered 0. use visualisation reinforce learnt earlier extend understanding logic behind Bayes factors.three settings visualisation, :Observed effect - Expressed Cohen's d, represents standardised mean difference two groups. can set larger effects (positive negative) assume null hypothesis true (d = 0).Observed effect - Expressed Cohen's d, represents standardised mean difference two groups. can set larger effects (positive negative) assume null hypothesis true (d = 0).Sample size - can increase sample size 1 1000, steps 1 100.Sample size - can increase sample size 1 1000, steps 1 100.SD prior - prior always set 0 testing null hypothesis, can specify strong prior . Decreasing SD means confident effect 0. Increasing SD means less certain prior.SD prior - prior always set 0 testing null hypothesis, can specify strong prior . Decreasing SD means confident effect 0. Increasing SD means less certain prior.visualisation set test null hypothesis difference two groups, remember Bayes factors allow test two hypotheses. Bayes factor represented difference two dots, curves represent likelihood 0 prior posterior distributions. Bayes factor ratio two values posterior odds much belief shift favour experimental hypothesis compared null hypothesis.Keep eye p-value 95% Confidence Interval (CI) see inferences similiar different statistical philosophy.reinforce lessons section 1 emphasis now Bayes factors, key observations:less informative prior (higher SD), posterior dominated likelihood show posterior overwhelmed data. example, set SD 2, prior peaks 0 distribution flat accepts reasonable effect. move observed effect anywhere along scale, likelihood posterior almost completely overlap reach d = ±2.less informative prior (higher SD), posterior dominated likelihood show posterior overwhelmed data. example, set SD 2, prior peaks 0 distribution flat accepts reasonable effect. move observed effect anywhere along scale, likelihood posterior almost completely overlap reach d = ±2.stronger prior (lower SD), posterior represents compromise prior likelihood. change SD 0.5 observed effect 1, posterior closer intermediary. may observed data, prior belief null effect strong enough requires data convinced otherwise.stronger prior (lower SD), posterior represents compromise prior likelihood. change SD 0.5 observed effect 1, posterior closer intermediary. may observed data, prior belief null effect strong enough requires data convinced otherwise.participants / data, less uncertainty likelihood. Keeping inputs point 2, 10 participants, likelihood peaks d = 1, easily spans 0 2. increase sample size towards 1000, uncertainty around likelihood lower. data also overwhelms prior, although relatively strong prior null effect, 50 participants, likelihood posterior mostly overlap.participants / data, less uncertainty likelihood. Keeping inputs point 2, 10 participants, likelihood peaks d = 1, easily spans 0 2. increase sample size towards 1000, uncertainty around likelihood lower. data also overwhelms prior, although relatively strong prior null effect, 50 participants, likelihood posterior mostly overlap.Focusing Bayes factor supporting experimental hypothesis, effect, evidence favour experimental hypothesis increases observed effect increases sample size increases. dissimilar frequentist statistical power, Bayesian statistics, optional stopping can less problem (Rouder (2014) see Schönbrodt et al. (2017) considerations must make). , enough data shift beliefs towards either hypothesis, can collect data update beliefs.Focusing Bayes factor supporting experimental hypothesis, effect, evidence favour experimental hypothesis increases observed effect increases sample size increases. dissimilar frequentist statistical power, Bayesian statistics, optional stopping can less problem (Rouder (2014) see Schönbrodt et al. (2017) considerations must make). , enough data shift beliefs towards either hypothesis, can collect data update beliefs.set observed effect 0, p-value 1 suggest reject null, remember support null. Bayes factors, can support null see observed effect = 0, sample size = 50, SD prior = 0.5, data 2.60 times likely null experimental hypothesis. , shift belief favour null, convincing. can obtain higher Bayes factor support null increasing sample size increasing SD prior. last part might sound little odd first, prior strong favour null (small SD), beliefs need shift light data.set observed effect 0, p-value 1 suggest reject null, remember support null. Bayes factors, can support null see observed effect = 0, sample size = 50, SD prior = 0.5, data 2.60 times likely null experimental hypothesis. , shift belief favour null, convincing. can obtain higher Bayes factor support null increasing sample size increasing SD prior. last part might sound little odd first, prior strong favour null (small SD), beliefs need shift light data.Finally, set weak prior (SD = 2), see frequentist 95% CI Bayesian 95% HDI almost identical. weak uninformative prior, values two intervals usually similar, must interpret differently. Increasing sample size makes intervals smaller changing observed effect shifts around. make stronger prior (SD = 0.5), now 95% HDI change move observed effect size around. frequentist 95% CI always follow likelihood based observed data. Bayesian 95% HDI represents area posterior, compromise prior likelihood, can smaller stronger prior favour null observed effect 0.Finally, set weak prior (SD = 2), see frequentist 95% CI Bayesian 95% HDI almost identical. weak uninformative prior, values two intervals usually similar, must interpret differently. Increasing sample size makes intervals smaller changing observed effect shifts around. make stronger prior (SD = 0.5), now 95% HDI change move observed effect size around. frequentist 95% CI always follow likelihood based observed data. Bayesian 95% HDI represents area posterior, compromise prior likelihood, can smaller stronger prior favour null observed effect 0.Based observations , try apply understanding questions using Magnusson's interactive app.Assuming moderate effect size d = 0.4 weak prior SD = 0.5, many participants per group need Bayes factor 3 favour alternative hypothesis? Assuming moderate effect size d = 0.4 weak prior SD = 0.5, many participants per group need Bayes factor 3 favour alternative hypothesis? Assuming moderate effect size d = 0.4 50 participants per group, use weaker prior SD = 2, evidence favour alternative hypothesis strongerweakerthe use stronger prior SD = 1.Assuming moderate effect size d = 0.4 50 participants per group, use weaker prior SD = 2, evidence favour alternative hypothesis strongerweakerthe use stronger prior SD = 1.opposite point 5 explanation . Remember Bayes factors represent shift belief one hypothesis compared another. confident null (smaller SD), take evidence shift belief favour alternative hypothesis difference.old rule thumb psychology 20 participants per group provide sufficient statistical power. Assuming moderate effect size d = 0.5 prior SD = 1, difference statistically significant (p = .049). However, looking guidelines provided lecture Wagenmakers et al. (2011), describe evidence favour alternative hypothesis? evidenceAnecdotalSubstantialStrong","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Bayes-independent-samples","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.4 Bayes factors for two independent samples","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"guided-example-bastian-et-al.-2014","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.4.1 Guided example (Bastian et al., 2014)","text":"first time used R chapter, need load packages data task. packages, make sure install first.guided example, reanalyse data Bastian et al. (2014). study wanted investigate whether experiencing pain together can increase levels bonding participants. study trying explain people often say friendships strengthened adversity.Participants randomly allocated two conditions: pain control. Participants pain group experienced mild pain cold pressor task (leaving hand ice cold water) wall squat (sitting wall). control group completed different task involve pain. participants completed scale measure bonded felt participants group. Higher values scale mean greater bonding.independent variable called \"CONDITION\". control group value 0 pain group value 1. wanted find whether participants pain group higher levels bonding fellow participants participants control group. little processing, dependent variable called \"mean_bonding\" mean 7 items related bonding.chapter predominantly use BayesFactor package (Morey & Rouder, 2022) functions applied t-tests. use Bayesian version t-test, use similar arguments base frequentist version stating design formula data frame referring . study, want predict bonding rating group allocated : mean_bonding ~ CONDITION.using t-tests, keep mind still applying linear model data despite using Bayesian rather frequentist statistics model uncertainty. going cover chapter, still check data parametric assumptions like normal residuals influential cases / outliers.Bayesian t-test, comparing null hypothesis 0 alternative hypothesis. data independent samples t-test, difference two groups. prior null point-null hypothesis assuming difference 0, prior alternative modelled Cauchy distribution. Bayes factor tells much shift belief towards one hypothesis compared another, either favour alternative null hypothesis.Bayesian t-test function, main new argument rscale sets width prior distribution around alternative hypothesis. T-tests use Cauchy prior similar normal distribution fatter tails define one parameter: r scale. figure visualises difference Cauchy normal distribution range r scale SD values.default prior set \"medium\", change depending understanding area research. See function help page different options , medium equivalent value 0.707 scaling Cauchy prior default setting statistics software. can interpret r scale 50% distribution covers values ± chosen value. effect zero likely, larger r scale value, plausible consider large effects. use value 0.707 (\"medium\") two-tailed test, means 50% prior distribution covers values ± 0.707. can enter numeric value precise scaling word presets like \"medium\", \"wide\", \"ultrawide\" depending strong weak want prior .worry warning, just previous issues using tibbles BayesFactor package. Now package converts tibbles normal R data frames thing.medium prior, Bayes factor 1.45 (\\(BF\\)\\(_1\\)\\(_0\\) = 1.45), suggesting experimental hypothesis 1.45 times likely point null hypothesis. guidelines Wagenmakers et al. (2011), quite weak anecdotal evidence.also percentage next Bayes factor. proportional error estimate tells error estimating Bayes factor value. Less error better rough rule thumb less 20% acceptable (Doorn et al., 2021). example, error estimate 0.01%, small. means expect Bayes factor range 1.44 1.45 makes little impact conclusion.","code":"\nlibrary(BayesFactor)\nlibrary(bayestestR)\nlibrary(tidyverse)\nBastian_data <- read_csv(\"data/Bastian.csv\")\n\n# Relabel condition to be more intuitive which group is which \nBastian_data$CONDITION <- factor(Bastian_data$CONDITION, \n                                   levels = c(0, 1), \n                                   labels = c(\"Control\", \"Pain\"))\n\n# We also need to get our DV from the mean of 7 items\nBastian_data <- Bastian_data %>% \n  pivot_longer(names_to = \"item\", # var for item names\n               values_to = \"score\", # var for item scores\n               cols = group101:group107) %>% # Range of columns for group bonding items\n  group_by(across(.cols = c(-item, -score))) %>% # Group by everything but ignore item and score\n  summarise(mean_bonding = mean(score)) %>% # Summarise by creating a subscale name and specify sum or mean\n  ungroup() # Always ungroup\nBastian_ttest <- ttestBF(formula = mean_bonding ~ CONDITION,\n                        data = Bastian_data,\n                        rscale = \"medium\", \n                        paired = FALSE)## Warning: data coerced from tibble to data frame\nBastian_ttest## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 : 1.445956 ±0.01%\n## \n## Against denominator:\n##   Null, mu1-mu2 = 0 \n## ---\n## Bayes factor type: BFindepSample, JZS"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"robustness-check","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.4.1.1 Robustness check","text":"important modelling next chapter, good practice check sensitivity results choice prior. exercise caution choice prior affects conclusions making, weak evidence turning strong evidence. qualitative conclusions change across plausible priors, findings robust. example, Bayes factor Bastian et al. example decreases prior r scale increases.wider prior expresses less certainty size effect; larger effects become plausible. Remember Bayes factors quantify degree belief one hypothesis compared another. evidence quite weak, Bayes factor decreases favour null weaker priors expressing less certainty size effect.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"one--vs-two-tailed-tests","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.4.1.2 One- vs two-tailed tests","text":"authors pretty convinced pain group score higher bonding rating control group, lets see happens one-tailed test see done. need define nullInterval argument state consider negative effects.Make sure check order groups check direction expect results go . expect group smaller group B, code negative effects. expect group bigger group B, code positive effects. common mistake defining wrong direction know order groups coded.one-tailed test, now two tests. row one, test want compare experimental hypothesis (negative effects) point null. row two, opposite complement experimental hypothesis, effect negative. Even one-tailed test, evidence favour experimental hypothesis compared null anecdotal best (\\(BF\\)\\(_1\\)\\(_0\\) = 2.79).wanted test null compared experimental hypothesis, can simply take reciprocal object, demonstrated two-tailed object.object, already know anecdotal evidence favour experimental hypothesis, just telling us null less likely experimental hypothesis (\\(BF\\)\\(_0\\)\\(_1\\) = 0.69). come handy specifically want test null though.purposes rest demonstration, stick original object two-tailed test see can interpret inconclusive results. original study, pain group scored significantly higher control group, p-value .048, hardly convincing evidence. Bayes factors, least can see ideally need data make decision.","code":"\nBastian_onetail <- ttestBF(formula = mean_bonding ~ CONDITION,\n                        data = Bastian_data,\n                        rscale = \"medium\", \n                        paired = FALSE,\n                        nullInterval = c(-Inf, 0)) # negative only as we expect control < pain## Warning: data coerced from tibble to data frame\nBastian_onetail## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 -Inf<d<0    : 2.790031  ±0%\n## [2] Alt., r=0.707 !(-Inf<d<0) : 0.1018811 ±0.02%\n## \n## Against denominator:\n##   Null, mu1-mu2 = 0 \n## ---\n## Bayes factor type: BFindepSample, JZS\n1 / Bastian_ttest## Bayes factor analysis\n## --------------\n## [1] Null, mu1-mu2=0 : 0.6915839 ±0.01%\n## \n## Against denominator:\n##   Alternative, r = 0.707106781186548, mu =/= 0 \n## ---\n## Bayes factor type: BFindepSample, JZS"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"parameter-estimation","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.4.1.3 Parameter estimation","text":"spend time process week/chapter 10, Bayes factor normally enough. also want estimate effect size precision around . Within BayesFactor package, function sample posterior distribution using MCMC sampling. need pass t-test object posterior function, include number iterations want. use 10,000 . Depending computer, may take seconds.use one-tailed test, must index first object (e.g., Bastian_ttest[1]) one-tailed test includes two lines: 1) directional alternative state null 2) complement alternative null.samples, can use base plot function see trace plots (chapter 10) density plot posterior distributions several parameters.second fourth plots mainly interested t-test. know kind evidence different hypotheses, typically want know effect size . BayesFactor package, get mean difference groups (unhelpfully named beta) effect size Delta, kind like Cohen's d. calculated dividing t statistic square root sample size, type standardised mean difference. One main complaints BayesFactor package explaining outputs mean explanation find old blog post clear overview documentation.plot provides posterior distribution different statistics based sampling 10,000 times. beta, can see peak distribution around -0.5, spanning 0 -1. delta, can see peak distribution around -0.5, spans 0 -1 .fine-tuned description posterior distribution, can use handy functions bayestestR package (Makowski et al., 2019). use much chapter 10 great plotting functions, functions work BayesFactor objects. get point estimates parameter, can use point_estimate function:best guess (median posterior) mean difference groups -0.49 delta -0.47 favour pain group.just want point estimate though, also want credible interval around . , hdi function., 95% posterior distribution mean difference -1.04 0.04, delta -0.99 0.04. values cross 0, confident findings ideally need collect data, consistent Bayes Factor results.Finally, instead separate functions, handy wrapper median, 95% credible interval, ROPE (later).bunch tests tricks covered , check Bayesfactor package page online series vignettes.","code":"\nBastian_samples <- posterior(Bastian_ttest,\n                            iterations = 1e5) # 10,000 in math notation\nplot(Bastian_samples)\npoint_estimate(Bastian_samples)\nhdi(Bastian_samples)\ndescribe_posterior(Bastian_samples)"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"reporting-your-findings","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.4.1.4 Reporting your findings","text":"reporting findings, Doorn et al. (2021) suggest several key pieces information provide reader:complete description justification prior;complete description justification prior;Clearly state hypothesis comparing specify using Bayes factor notation (\\(BF\\)\\(_0\\)\\(_1\\) \\(BF\\)\\(_1\\)\\(_0\\));Clearly state hypothesis comparing specify using Bayes factor notation (\\(BF\\)\\(_0\\)\\(_1\\) \\(BF\\)\\(_1\\)\\(_0\\));Bayes factor value error percentage;Bayes factor value error percentage;robustness check findings different plausible priors;robustness check findings different plausible priors;parameter estimate (effect size) including posterior mean median 95% credible / highest density interval (HDI).parameter estimate (effect size) including posterior mean median 95% credible / highest density interval (HDI).possible, try provide reader results graphical numerical form, including plot posterior distribution. easier next chapter plotting helper functions work nicely BayesFactor package.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Schroeder-activity","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.4.2 Independent activity (Schroeder & Epley, 2015)","text":"independent activity, use data Schroeder & Epley (2015). aim study investigate whether delivering short speech potential employer effective landing job writing speech employer reading . Thirty-nine professional recruiters randomly assigned receive job application speech either transcript read, audio recording applicant reading speech.recruiters rated applicants perceived intellect, impression applicant, whether recommend hiring candidate. ratings originally Likert scale ranging 0 (low intellect, impression etc.) 10 (high impression, recommendation etc.), final value representing mean across several items.example, focus hire rating (variable \"Hire_Rating\" see whether audio condition lead higher ratings transcript condition (variable \"CONDITION\")., apply learnt first guided example new independent task complete questions check understanding. Since expect higher ratings audio transcript, use one-tailed test. Remember sample posterior, can also get estimates effect sizes.can check attempt solutions bottom page.Rounding two decimals, Bayes Factor favour alternative hypothesis? Rounding two decimals, Bayes Factor favour alternative hypothesis? Looking guidelines Wagenmakers et al. (2015), describe evidence favour alternative hypothesis? NoAnecdotalSubstantialStrongLooking guidelines Wagenmakers et al. (2015), describe evidence favour alternative hypothesis? NoAnecdotalSubstantialStrongRounding two decimals, absolute (ignoring sign) mean difference (beta) favour audio condition? Rounding two decimals, absolute (ignoring sign) mean difference (beta) favour audio condition? Looking 95% credible interval, can rule effect 0 given data model? YesNoLooking 95% credible interval, can rule effect 0 given data model? YesNo","code":"\nSchroeder_data <- read_csv(\"data/Schroeder_hiring.csv\")\n\n# Relabel condition to be more intuitive which group is which \nSchroeder_data$CONDITION <- factor(Schroeder_data$CONDITION, \n                                   levels = c(0, 1), \n                                   labels = c(\"Transcript\", \"Audio\"))\nSchroeder_ttest <- NULL"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Bayes-dependent-samples","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.5 Bayes factors for two dependent samples","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"guided-example-mehr-et-al.-2016","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.5.1 Guided example (Mehr et al., 2016)","text":"paired samples t-test, process identical independent samples t-test apart defining variables. , demonstrate full example like less commentary, independent data frame test understanding.next study going look Mehr et al. (2016). interested whether singing infants conveyed important information social affiliation. Infants become familiar melodies repeated specific culture. authors interested whether novel person (someone never seen ) signal child member social group attract attention singing familiar song .Mehr et al. (2016) invited 32 infants parents participate repeated measures experiment. First, parents asked repeatedly sing previously unfamiliar song infants two weeks. returned lab, measured baseline gaze (looking) infants towards two unfamiliar people screen just silently smiling . measured proportion time looking individual later sing familiar song (0.5 indicate half time spent looking familiar singer. Values closer one indicate looking longer). two silent people screen took turns sing lullaby. One people sung song infant’s parents told sing previous two weeks, one sang song lyrics rhythm, different melody. Mehr et al. (2016) repeated gaze procedure two people start experiment provide second measure gaze proportion looking familiar singer.interested whether infants increased proportion time spent looking singer sang familiar song sang, comparison sang infants. one dependent variable (gaze proportion) one within-subjects independent variable (baseline vs test). want know whether gaze proportion higher test (\"Test_Proportion_Gaze_to_Singer\") baseline (\"Baseline_Proportion_Gaze_to_Singer\").Like Bastian et al. (2014), just anecdotal evidence favour experimental hypothesis null (\\(BF\\)\\(_1\\)\\(0\\) = 2.30).Mehr et al. (2016) expected gaze proportion higher test, try defining one-tailed test see kind evidence favour alternative hypothesis., know anecdotal evidence favour experimental hypothesis, also want effect size 95% credible interval. , can sample posterior, plot , get estimates.Just note plot fewer panels paired samples approach simplifies things. Mu mean difference first panel delta standardised effect third panel. dependent variable like gaze proportion, unstandardised effect size informative comparable across studies, also useful report standardised effect sizes future power analyses etc.finally wrapper function median posterior distribution 95% credible interval.can see median posterior estimate mean difference -.07 95% credible interval ranging -.13 -.01. dependent variable measured proportion gaze time, infants looked familiar singer 7% (1-13% 95% credible interval) longer test baseline. means can exclude 0 likely effects, still anecdotal evidence favour experimental hypothesis compared null.","code":"\nMehr_data <- read_csv(\"data/Mehr_voice.csv\") %>% \n  select(Baseline = Baseline_Proportion_Gaze_to_Singer, # Shorten super long names\n         Test = Test_Proportion_Gaze_to_Singer)\n\nMehr_ttest <- ttestBF(x = Mehr_data$Baseline,\n                      y = Mehr_data$Test,\n                      paired = TRUE, \n                      rscale = \"medium\")\n\nMehr_ttest## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 : 2.296479 ±0%\n## \n## Against denominator:\n##   Null, mu = 0 \n## ---\n## Bayes factor type: BFoneSample, JZS\nMehr_samples <- posterior(Mehr_ttest,\n                          iterations = 1e5)\n# Subset first plot for mean to display correctly\nplot(Mehr_samples[, 1],\n     main = \"Posterior for mu\")\n# Subset third plot for delta to display correctly\nplot(Mehr_samples[, 3],\n     main = \"Posterior for delta\")\ndescribe_posterior(Mehr_samples)"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Zwaan-activity","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.5.2 Independent activity (Zwaan et al., 2020)","text":"final independent activity, data Zwaan et al. (2018) wanted see replicable experiments cognitive psychology . exercise, explore flanker task.short, two conditions: congruent incongruent. congruent trials, five symbols like arrows participants must identify central symbol keyboard response. incongruent trials, four outer symbols different central symbol. Typically, find participants respond faster congruent trials incongruent trials. dependent variable mean response time milliseconds (ms).want know whether response times faster congruent trials (\"session1_responsecongruent\") incongruent trials (\"session1_incongruent\"). Zwaan et al. measured things like changing stimuli repeating task two sessions, just focus first session example.Perform paired samples t-test comparing response times congruent incongruent trials. questions relate one-tailed test since strong prediction expect faster responses congruent condition compared incongruent condition. Think carefully whether expect positive negative effects depending order enter variables.can check attempt solutions bottom page.Looking guidelines Wagenmakers et al. (2011), describe evidence favour alternative hypothesis? SubstantialStrongVery strongExtremeThe Bayes Factor analysis huge. Unless edit settings, R reports large numbers scientific notation. Bayes Factor favour alternative hypothesis 8.7861e+12 real number 8786100000000. finding established flanker task, testing point null informative, shows extreme evidence looks like. come back ROPE demonstration later.Rounding two decimals, absolute (ignoring sign) mean difference (beta) response time congruent incongruent trials? Rounding two decimals, absolute (ignoring sign) mean difference (beta) response time congruent incongruent trials? Looking 95% credible interval mu, expect absolute mean difference range 30.0638.7847.54ms 30.0638.7847.54ms.Looking 95% credible interval mu, expect absolute mean difference range 30.0638.7847.54ms 30.0638.7847.54ms.Rounding two decimals, absolute standardised mean difference (delta) response time congruent incongruent trials? Rounding two decimals, absolute standardised mean difference (delta) response time congruent incongruent trials? ","code":"\nZwaan_data <- read_csv(\"data/Zwaan_flanker.csv\")\n\nZwaan_ttest <- NULL"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"ROPE","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.6 Equivalence Testing vs ROPE","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"guided-example-for-two-independent-samples-bastian-et-al.-2014","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.6.1 Guided example for two independent samples (Bastian et al., 2014)","text":"sections 9.4 9.5, focused Bayesian approach null hypothesis testing. compared alternative hypothesis null hypothesis wanted know much shift beliefs. However, times comparing point null uninformative. advice applies frequentist statistics can use equivalence testing (see bonus section appendix interested ). setup, set two boundaries representing smallest effect size interest (SESOI) conduct two one-sided test: one comparing sample mean (difference) upper bound one comparing sample mean (difference) lower bound. tests significant, can conclude mean within bounds practically equivalent zero.Bayesian framework, follow similar approach setting upper lower bound interval consider practically theoretically meaningful. known Region Practical Equivalence (ROPE). However, perform two one-sided test, directly compare posterior distribution ROPE interpret much ROPE captures 95% credible interval. creates three decisions (Kruschke & Liddell, 2018a) instead comparing experimental hypothesis point null:HDI completely outside ROPE: reject ROPE parameter larger effects consider small practically/theoretically meaningful.HDI completely outside ROPE: reject ROPE parameter larger effects consider small practically/theoretically meaningful.HDI completely within ROPE: accept ROPE parameter smaller effects consider practically/theoretically meaningful.HDI completely within ROPE: accept ROPE parameter smaller effects consider practically/theoretically meaningful.HDI ROPE partially overlap: undecided need data greater precision posterior make decision whether can reject ROPE.HDI ROPE partially overlap: undecided need data greater precision posterior make decision whether can reject ROPE.meaningful chapter 10 turn Bayesian modelling bayestestR package great functions visualising ROPE, unfortunately work BayesFactor objects. return Bastian et al. (2014) data describe_posterior() function. explored complete output earlier, might noticed values relating ROPE, ignored time. reminder, lets see output:information ROPE within bayestestR package, see online vignettes. output, :95% credible interval - need compare ROPE.95% credible interval - need compare ROPE.probability direction (pd) - much posterior distribution positive negative direction?probability direction (pd) - much posterior distribution positive negative direction?Region practical equivalence (ROPE) - interval consider SESOI.Region practical equivalence (ROPE) - interval consider SESOI.% ROPE - much posterior within ROPE?% ROPE - much posterior within ROPE?default, describe_posterior() function sets ROPE region mean plus minus 0.1 * SD response. can set ROPE using rope_range argument. Justifying ROPE probably difficult decision make requires subject knowledge consider smallest effect size interest. lecture, different strategies:understanding applications / mechanisms (e.g., clinically meaningful decrease pain).understanding applications / mechanisms (e.g., clinically meaningful decrease pain).Smallest effects previous research (e.g., lower bound individual study effect sizes lower bound meta-analysis).Smallest effects previous research (e.g., lower bound individual study effect sizes lower bound meta-analysis).Small telescopes (effect size original study 33% power detect).Small telescopes (effect size original study 33% power detect).Bastian et al. (2014), measured bonding 5-point Likert scale, might consider anything less one-point difference small practically meaningful.Note changing ROPE range changes values every parameter, need think parameter interested justifiable ROPE . example, focus mean difference groups (beta). Using ROPE plus minus 1, 99.26% 95% HDI within ROPE. close, falls third decision need data make decision. lower bound HDI -1.03, extends just outside ROPE region.Compared standard Bayes factor weak evidence favour alternative hypothesis compared point null, using ROPE approach means also inconclusive decision, effect size almost small practically meaningful.","code":"\n# rerun the code from section 9.4.1 if you do not have this object saved\ndescribe_posterior(Bastian_samples)\ndescribe_posterior(Bastian_samples,\n                   rope_range = c(-1, 1)) # plus or minus one point difference"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"independent-activity-for-two-independent-samples-schroeder-epley-2014","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.6.2 Independent activity for two independent samples (Schroeder & Epley, 2014)","text":"activity, need objects created section 9.4.2 independent activity. Remember based one-tailed t-test expected higher ratings audio group compared transcript group. need samples posterior thing need change arguments use describe_posterior() function.Use describe_posterior() section 9.4.2, time enter values ROPE arguments. original study 10-point scale. choice ROPE depend understanding subject area, measured outcomes 0-10 scale. might higher bar concluding meaningful effect medium people's hire ratings, use ROPE region 2 points. Since used one-tailed test focusing negative effects (transcript < audio), can just focus region -2 0.can check attempt solutions bottom page.Looking 95% credible interval beta, expect absolute mean difference range 0.322.943.114.52 0.322.943.114.52.Looking 95% credible interval beta, expect absolute mean difference range 0.322.943.114.52 0.322.943.114.52.Rounding two decimals, percentage 95% credible interval within ROPE? Rounding two decimals, percentage 95% credible interval within ROPE? appropriate conclusion based ROPE?:\n\nHDI completely outside ROPE: reject ROPE.HDI completely within ROPE: accept ROPE.HDI ROPE partially overlap: undecided need data.\nappropriate conclusion based ROPE?:","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"guided-example-for-two-dependent-samples-mehr-et-al.-2014","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.6.3 Guided example for two dependent samples (Mehr et al., 2014)","text":"Mehr et al. (2014) data, outcome little easier interpret unstandardised effect two -subjects examples. compared infants' proportion gaze duration spent model sang familiar song wanted know whether increase test compared baseline. proportion gaze bound 0 (none time) 1 (time), might consider 5% (0.05) increase decrease theoretically meaningful certain test higher baseline.observed mean difference posterior median -0.07, 95% CI = [-.13, -0.01], 27.50% within ROPE region plus minus 0.05 points. far ruling ROPE, still need data make decision. Hopefully, can see point, many studies inconclusive conclusions analysed Bayesian framework original frequentist statistics.","code":"\ndescribe_posterior(Mehr_samples,\n                   rope_range = c(-0.05, 0.05))"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"independent-activity-for-two-dependent-samples-zwaan-et-al.-2018","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.6.4 Independent activity for two dependent samples (Zwaan et al., 2018)","text":"activity, need objects created section 9.5.2 independent activity. Remember based one-tailed t-test expected faster response times congruent trials incongruent trials. need samples posterior thing need change arguments use describe_posterior() function.Use describe_posterior() section 9.5.2, time enter values ROPE arguments. Set ROPE -10-0ms (0-10 depending order entered variables) smaller effects closer sampling error can expect response time experiments held online (Reimers & Stewart, 2015).can check attempt solutions bottom page.Looking 95% credible interval mu, expect absolute mean difference range 30.0631.4838.7847.54 30.0631.4838.7847.54.Looking 95% credible interval mu, expect absolute mean difference range 30.0631.4838.7847.54 30.0631.4838.7847.54.percentage 95% credible interval within ROPE? percentage 95% credible interval within ROPE? appropriate conclusion based ROPE?:\n\nHDI completely outside ROPE: reject ROPE.HDI completely within ROPE: accept ROPE.HDI ROPE partially overlap: undecided need data.\nappropriate conclusion based ROPE?:","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"summary","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.7 Summary","text":"chapter, learnt hypothesis testing using Bayesian framework. first two activities explored logic Bayesian statistics make inferences can used test hypotheses expressed Bayes factor. learnt perform Bayes factors applied simplest cases two independent samples two dependent samples. Bayes factors useful way quantifying evidence favour hypotheses compared competing hypothesis. Bayesian statistics can still used mindlessly, hopefully can see provide opportunity move away purely dichotomous thinking. Evidence statistically significant (p < .05) close alpha represents anecdotal evidence.new skill, practice best approach becoming comfortable applying knowledge novel scenario. Hopefully, worked guided examples tested understanding independent activities.learning, recommend following resources relevant chapter:Doorn et al. (2021) - Although focuses JASP software, article provides accessible introduction Bayes factors can report findings.Doorn et al. (2021) - Although focuses JASP software, article provides accessible introduction Bayes factors can report findings.Kruschke & Liddell (2018b) - article discusses proposed shift away dichotomous hypothesis testing towards estimation relates Bayesian statistics summarising posterior ROPE procedure.Kruschke & Liddell (2018b) - article discusses proposed shift away dichotomous hypothesis testing towards estimation relates Bayesian statistics summarising posterior ROPE procedure.Wong et al. (2021) - Although Bayes factors potential help make nuanced inferences, still prone misinterpretations. preprint outlines common errors misconceptions researcher report Bayes factors.Wong et al. (2021) - Although Bayes factors potential help make nuanced inferences, still prone misinterpretations. preprint outlines common errors misconceptions researcher report Bayes factors.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"independent-activity-solutions","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.8 Independent activity solutions","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Schroeder-solution","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.8.1 Schroeder and Epley (2015) Bayes factor","text":"","code":"\nSchroeder_ttest <- ttestBF(formula = Hire_Rating ~ CONDITION,\n        data = Schroeder_data, \n        rscale = \"medium\",\n        nullInterval = c(-Inf, 0)) # Expect negative effects since Transcript < Audio## Warning: data coerced from tibble to data frame\nSchroeder_ttest## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 -Inf<d<0    : 8.205739  ±0%\n## [2] Alt., r=0.707 !(-Inf<d<0) : 0.1020371 ±0%\n## \n## Against denominator:\n##   Null, mu1-mu2 = 0 \n## ---\n## Bayes factor type: BFindepSample, JZS\n# We need to index the first object as a one-tailed test includes two lines: \n# 1. Directional alternative we state against the null\n# 2. Complement of the alternative against the null\n\nSchroeder_samples <- posterior(Schroeder_ttest[1], \n                               iterations = 1e5)\nplot(Schroeder_samples)\ndescribe_posterior(Schroeder_samples)"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Zwaan-solution","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.8.2 Zwaan et al. (2020) Bayes factor","text":"","code":"\nZwaan_ttest <- ttestBF(x = Zwaan_data$session1_responsecongruent,\n                      y = Zwaan_data$session1_incongruent,\n                      paired = TRUE, \n                      rscale = \"medium\",\n                      nullInterval = c(-Inf, 0)) # negative as we expect incongruent to be larger than congruent## t is large; approximation invoked.\n## t is large; approximation invoked.\nZwaan_ttest## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 -Inf<d<0    : 8.786135e+12 ±NA%\n## [2] Alt., r=0.707 !(-Inf<d<0) : 0.00599365   ±NA%\n## \n## Against denominator:\n##   Null, mu = 0 \n## ---\n## Bayes factor type: BFoneSample, JZS\nZwaan_samples <- posterior(Zwaan_ttest[1], # index first item for a one-tailed test\n                          iterations = 1e5)\nplot(Zwaan_samples[, 1],\n     main = \"Posterior for mu\")\nplot(Zwaan_samples[, 3], \n     main = \"Posterior for delta\")\ndescribe_posterior(Zwaan_samples)"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Schroeder-ROPE-solution","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.8.3 Schroeder and Epley (2015) ROPE","text":"","code":"\ndescribe_posterior(Schroeder_samples,\n                   rope_range = c(-2, 0))"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"Zwaan-ROPE-solution","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.8.4 Zwaan et al. (2020) ROPE","text":"","code":"\ndescribe_posterior(Zwaan_samples,\n                   rope_range = c(-10, 0))"},{"path":"introduction-to-bayesian-estimation.html","id":"introduction-to-bayesian-estimation","chapter":"10 Introduction to Bayesian Estimation","heading":"10 Introduction to Bayesian Estimation","text":"chapter, learn Bayesian approach estimation fitting regression models using brms package (Bürkner, 2017). flexible approach modelling can select relevant outcome predictors rather relying ---box statistical tests. focusing estimation exploring posterior model make inferences. build skills learnt chapter 9, extending flexible priors statistical models. mainly going focus simple multiple linear regression chapter, final section outlines resources learn advanced distribution families models.always welcome provide feedback resources, book part new suite materials developing. comments, please complete online short anonymous form contact one lecturing team directly.","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"learning-objectives-1","chapter":"10 Introduction to Bayesian Estimation","heading":"10.1 Learning objectives","text":"end chapter, able :Understand steps involved fitting exploring Bayesian regression models.Understand steps involved fitting exploring Bayesian regression models.Apply steps simple linear regression.Apply steps simple linear regression.Apply steps multiple linear regression.Apply steps multiple linear regression.Create data visualisation graphically communication results Bayesian regression models.Create data visualisation graphically communication results Bayesian regression models.follow along chapter try code , please download data files using zip file.chapter, need extra packages. one likely cause trouble main brms package since uses Stan need C++ compiler. See installing R appendix guidance. really struggling slow computer, brms available R Studio server. See course overview page link never used .","code":"\nlibrary(brms) # fitting Bayesian models\nlibrary(bayestestR) # helper functions for plotting and understanding the models\nlibrary(tidybayes) # helper functions for combining plotting and tidy data from models\nlibrary(tidyverse)\nlibrary(see) # helper functions for plotting objects from bayestestR\nlibrary(emmeans) # Handy function for calculating (marginal) effect sizes\nlibrary(patchwork) # Combine multiple plots"},{"path":"introduction-to-bayesian-estimation.html","id":"simpleregression","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2 Simple Linear Regression","text":"","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"guided-example-schroeder-epley-2015","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.1 Guided example (Schroeder & Epley, 2015)","text":"guided activity, use data study Schroeder & Epley (2015). used chapter 9 independent activity, explore data set guided example chapter see can refit Bayesian regression model.reminder, aim study investigate whether delivering short speech potential employer effective landing job writing speech employer reading . Thirty-nine professional recruiters randomly assigned receive job application speech either transcript read audio recording reading speech.recruiters rated applicants perceived intellect, impression applicant, whether recommend hiring candidate. ratings originally Likert scale ranging 0 (low intellect, impression etc.) 10 (high impression, recommendation etc.), final value representing mean across several items.example, focus hire rating (variable \"Hire_Rating\") see whether audio condition lead higher ratings transcript condition (variable \"CONDITION\").Remember key steps Bayesian modelling lecture 10 (Heino et al., 2018):Identify data relevant research questionIdentify data relevant research questionDefine descriptive model, whose parameters capture research questionDefine descriptive model, whose parameters capture research questionSpecify prior probability distributions parameters modelSpecify prior probability distributions parameters modelUpdate prior posterior distribution using Bayesian inferenceUpdate prior posterior distribution using Bayesian inferenceCheck model data, identify potential problemsCheck model data, identify potential problems","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"identify-data","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.1.1 Identify data","text":"example, data Schroeder Epley one outcome one categorical predictor. data coded 0 transcript group 1 audio group.","code":"\nSchroeder_data <- read_csv(\"data/Schroeder_hiring.csv\") %>% \n  mutate(CONDITION = as.factor(CONDITION))"},{"path":"introduction-to-bayesian-estimation.html","id":"define-a-descriptive-model","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.1.2 Define a descriptive model","text":"next step define descriptive model. chapter 9, used BayesFactor package use ---box tests like t-test, saw lecture Lindelöv (2019) blog post, common statistical models just different expressions linear models. , can express t-test linear model, using \"CONDITION\" single categorical predictor \"Hire_Rating\" outcome. can enter directly brm() function , normally good idea clearly outline component.","code":"\nSchroeder_model1 <- bf(Hire_Rating ~ CONDITION)"},{"path":"introduction-to-bayesian-estimation.html","id":"specify-prior-probability-of-parameters","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.1.3 Specify prior probability of parameters","text":"get used brms package, start learn priors need simple cases, now stated model, can see parameters can assigned prior.tells us priors can set default settings . prior, class prior, relevant coefficients, source default now. prior tells default . example, flat uninformative priors coefficients. set priors, can either set priors whole class, specific coefficient. one predictor, one coefficient prior set, makes difference. multiple predictors like later chapter 10, becomes useful.Coefficients assigned flat priors, meaning anything possible minus infinity infinity. can visualise priors see expect one--one. see can plot priors shortly.intercept sigma assigned student t distributions priors, full intercept half student t sigma. quite weak priors minimal influence model, factor knowledge parameters. default prior intercept peaks slightly 0 likely -5 15.default prior sigma half student t distribution peaks 0. plot demonstrates full student t distribution, sigma smaller 0, extend 0 positive values.example, can define informative priors using information Schroeder Epley. paper contains four studies data set focuses fourth apply findings professional recruiters. Study 1 preceded used students, can pretend researchers use source priors \"later\" study.Focusing hire rating, found (pg. 881):\"Evaluators heard pitches also reported significantly likely hire candidates (M = 4.34, SD = 2.26) evaluators read exactly pitches (M = 3.06, SD = 3.15), t(156) = 2.49, p = .01, 95% CI difference = [0.22, 2.34], d = 0.40 (see Fig. 1)\"., intercept reference group, can set normally distributed prior around mean 3 SD 3 transcript group. Note rounded values since approximations expect measures manipulations. factoring know parameters topic method knowledge.normally good idea visualise process check numbers enter match expectations. intercept, mean SD 3 look like generating numbers normal distribution:turns quite weak prior since distribution extends 0 (possible scale) way 10 upper limit scale. covers pretty much entire measurement scale peak around 3, represents lenient estimate expect reference group .can set something informative sigma prior knowing standard deviations. common prior standard deviation using exponential distribution lower 0. means largest density around zero density decreases across positive values. one value enter exponential distribution: rate parameter. Values closer zero cover wider range, larger values cover smaller range. , value 1 means peak 0 drops 2 beyond.Note visualisation: Credit visualisation method goes Andrew Heiss shared code Github Gist visualise different priors. adapted code use help visualise priors enter. can adapt code show kind prior used brms models. need specify distribution family parameters. Like original code, can even present bunch options compare side side.coefficient, mean difference around 1 (calculated manually subtracting one mean ) 95% confidence interval quite wide 0.22 2.34. working prior best fit knowledge, can compare different options side side. can compare stronger prior (SD = 0.5) vs weaker prior (SD = 1).stronger prior left shows expecting mainly positive effects peak 1 ranges around -0.5 (transcript higher audio) 2 (audio higher transcript). weaker prior right shows still expecting peak 1, span -1.5 around 3.5.Lets say think positive negatives effects plausible expect likely outcome similar study 1 Schroeder Epley. , example go weaker prior. Now priors, can save new object:Remember important check sensitivity results choice prior. , finished, check stable results uninformative prior, keeping defaults. Normally opposite way around using uninformative priors first, want put thinking priors.","code":"\nget_prior(Schroeder_model1, # Model we defined above\n          data = Schroeder_data) # Which data frame are we using? \npriors <- c(prior(normal(1, 0.5), class = b),\n            prior(normal(1, 1), class = b)) # Set prior and class\n\npriors %>% \n  parse_dist() %>% # Function from tidybayes/ggdist to turn prior into a dataframe\n  ggplot(aes(y = 0, dist = .dist, args = .args, fill = prior)) + # Fill in details from prior and add fill\n  stat_slab(normalize = \"panels\") + # ggdist layer to visualise distributions\n  scale_fill_viridis_d(option = \"plasma\", end = 0.9) + # Add colour scheme\n  guides(fill = \"none\") + # Remove legend for fill\n  facet_wrap(~prior) + # Split into a different panel for each prior\n  labs(x = \"Value\", y = \"Density\") +\n  theme_classic()\npriors <- set_prior(\"normal(1, 1)\", class = \"b\") + \n  set_prior(\"normal(3, 3)\", class = \"Intercept\") + \n  set_prior(\"exponential(1)\", class = \"sigma\")"},{"path":"introduction-to-bayesian-estimation.html","id":"update-the-prior-to-the-posterior","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.1.4 Update the prior to the posterior","text":"going longest section going fit brms model explore posterior.process relies sampling using MCMC, important set seed within function reproducibility, semi-random numbers consistent starting point. might take depending computer, get bunch output fitting model sampling MCMC chains.lots data complicated models, fitting process can take long time. means normally good idea save fitted model save time want look quickly. brm function, argument called file. write character string file directory name want save . Models saved .rds file - R's data file format can save objects . Behind scenes book, must run code every time want update , models see based reading models .rds files first fitted models. save objects, remember refit change anything like priors, model, data. file already exists though, overwritten unless use file_refit argument.save model .rds file, can load using read_rds() function readr tidyverse.lot output explain fitting sampling process. longer explanation MCMC sampling works, see Ravenzwaaij et al. (2018), quick overview, want sample posterior distribution based data model. default brms sample four chains, chain containing 2000 iterations (1000 warm / burn iterations). get warning messages model fit convergence issues, can increase number iterations. becomes important complex models, defaults fine relatively simple models fit chapter. return chains convergence see trace plots later.Now fitted model, can also double check priors set wanted. see source priors set switched default user.Now model, can get model summary like old linear model R.top, information model fitting process, like family, data, draws posterior summarising chain iterations.Population-level effects main area interest. posterior probability distribution summary statistics. look whole distribution soon, now, can see median point-estimate intercept 3.01 95% credible interval 2.09 3.94. expect mean reference group , .e., transcript group.median coefficient 1.57 95% credible interval 0.46 2.66. means best guess mean difference / slope increase 1.57 audio group. Note, might get subtly different values output since based semi-random sampling process, qualitative conclusions .convergence issues, Rhat different 1, can suggest problems model fitting process. can also look effective sample size statistics (columns ending ESS). thousands, least hundreds (Flores et al., 2022) bulk tail. return final indicator model fitting soon check trace plots.tidier summary parameters, can also use handy describe_posterior() function bayestestR.can use way create ROPE regions effects tells us useful things like probability direction effect (much posterior zero).","code":"\nSchroeder_fit <- brm(\n  formula = Schroeder_model1, # formula we defined above \n  data = Schroeder_data, # Data frame we're using \n  family = gaussian(), # What distribution family do we want for the likelihood function? Many examples we use in psychology are Gaussian, but check the documentation for options\n  prior = priors, # priors we stated above\n  sample_prior = TRUE, # Setting this to true includes the prior in the object, so we can include it on plots later\n  seed = 1908,\n  file = \"Models/Schroeder_model1\" #Save the model as a .rds file\n)\nSchroeder_fit <- read_rds(\"Models/Schroeder_model1.rds\")\nprior_summary(Schroeder_fit)\nsummary(Schroeder_fit)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: Hire_Rating ~ CONDITION \n##    Data: Schroeder_data (Number of observations: 39) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept      3.01      0.47     2.09     3.94 1.00     3402     2862\n## CONDITION1     1.57      0.57     0.46     2.66 1.00     3449     2879\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     2.17      0.25     1.74     2.71 1.00     3617     2850\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\ndescribe_posterior(Schroeder_fit)"},{"path":"introduction-to-bayesian-estimation.html","id":"plotting-the-posterior-distributions","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.1.4.1 Plotting the posterior distributions","text":"now, focused point-estimates intervals posterior, main strength Bayesian statistics summarising parameters whole posterior probability distribution, now turn various plotting options.first plot useful seeing posterior parameter trace plots check convergence issues.model, three plots: one intercept, one coefficient/slope, one sigma. left, posterior probability distributions . right, trace plots. default, brms uses four chains - series samples using MCMC - shows chain moves around parameter space. Essentially, want trace plots look like fuzzy caterpillars random series lines. spike deviate massively rest, lines get stuck one area, suggests convergence issues.plots useful initial feel parameter posteriors, great series functions bayestestR package (Makowski et al., 2019) can use , wrap plot() function loading see package (Lüdecke et al., 2021). example, can see overlay prior posterior main parameters interest. , p_direction() tells probability direction parameter, .e., much distribution 0? Wrapped plot(), can see prior posterior, posterior divided areas 0.work, must specify priors brms. work package default options coefficients.can see pretty wide prior blue, posterior. Almost posterior distribution zero show pretty confident audio associated higher hire ratings transcript.next useful plot seeing 95% HDI / credible interval. , hdi() show 95% HDI parameters. Wrapped plot(), can visualise HDI compared zero main parameters. HDI excludes zero, can confident positive negative effect, least conditional data model. Remember, difference small world big world models. absolute truth, just credible values conditioned data model.plots informative learning model inferences can learn . However, immediately suitable enter report. Fortunately, created using ggplot, can customise way adding layers additional functions.example, 95% HDI excludes 0, can confident coefficient posterior positive effect, audio group leading higher hire ratings transcript group.Finally, might interested comparing coefficients point-value 0, might stronger level evidence mind, coefficient must exclude range values ROPE process explored chapter 9. example, maybe effects smaller 1 unit difference small practically/theoretically meaningful.Remember potentially difficult decision make, maybe choosing priors. Many areas psychology clear guidelines/expectations smallest effect sizes interest, explain justify approach based understanding topic area.example, sample size 39, pretty strong evidence favour positive effect audio group. 95% HDI excludes zero, set ROPE 1 unit, quite exclude . means wanted confident effect exceeded ROPE, need data. just demonstration purposes, sure original study consider effect 1 practically meaningful, whether just happy non-zero effect.","code":"\nplot(Schroeder_fit)\nplot(p_direction(Schroeder_fit), \n     priors = TRUE) \nplot(bayestestR::hdi(Schroeder_fit)) # Specify package to avoid clash with ggdist\nplot(rope(Schroeder_fit, \n          range = c(-1, 1))) # What is the ROPE range for your smallest effects of interest? "},{"path":"introduction-to-bayesian-estimation.html","id":"hypothesis-testing-in-brms","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.1.4.2 Hypothesis testing in brms","text":"Following chapter 9, saw can also use Bayesian statistics test hypotheses. works modelling approach brms function test hypotheses. must provide fitted model object state hypothesis test. relies character description parameter test value. full explanation, see brms documentation online function. , test coefficient/slope point-null 0.must state character hypothesis requires select parameter. , focus \"CONDITION\" parameter, .e., slope, must match name model. can state values test , like point-null 0 Bayes factor. Alternatively, can test posterior odds compare masses posterior like CONDITION > 0.key part output evidence ratio (Evid.Ratio), also estimate 95% credible interval. testing point-null 0, testing null hypothesis alternative non-null effect. value 1, suggests evidence favour alternative compared null. prefer express things 1 easier interpret. can dividing 1 ratio, provide Bayes factor 12.5 .Alternatively, can calculate posterior odds stating regions posterior test. example, used \"CONDITION1 > 0\", provide ratio posterior probability positive effects 0 posterior probability negative effects 0. example, posterior odds 265.7 favour positive effects. Note, posterior 0, can get result Inf (infinity) evidence favour positive effects.","code":"\nhypothesis(Schroeder_fit, # brms model we fitted earlier\n           hypothesis = \"CONDITION1 = 0\") ## Hypothesis Tests for class b:\n##         Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob\n## 1 (CONDITION1) = 0     1.57      0.57     0.46     2.66       0.08      0.08\n##   Star\n## 1    *\n## ---\n## 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n## '*': For one-sided hypotheses, the posterior probability exceeds 95%;\n## for two-sided hypotheses, the value tested against lies outside the 95%-CI.\n## Posterior probabilities of point hypotheses assume equal prior probabilities.\nhypothesis(Schroeder_fit, # brms model we fitted earlier\n           hypothesis = \"CONDITION1 > 0\") ## Hypothesis Tests for class b:\n##         Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob\n## 1 (CONDITION1) > 0     1.57      0.57     0.63      2.5     265.67         1\n##   Star\n## 1    *\n## ---\n## 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n## '*': For one-sided hypotheses, the posterior probability exceeds 95%;\n## for two-sided hypotheses, the value tested against lies outside the 95%-CI.\n## Posterior probabilities of point hypotheses assume equal prior probabilities."},{"path":"introduction-to-bayesian-estimation.html","id":"calculating-and-plotting-conditional-effects","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.1.4.3 Calculating and plotting conditional effects","text":"final part exploring posterior, might interested estimates group condition predictor. two groups, can calculate point estimate using intercept slope, can use emmeans package (Lenth, 2022) calculate conditional effects posterior distribution.provides median 95% HDI values posterior group. brms package also comes function called conditional_effects() can use plot conditional effects.default, plots median posterior group error bars represent 95% HDI around median. Behind scenes, uses ggplot, can customise graphs make better suited report.use conditional_effects() function, type plot produces depend data type. way back read data , turned CONDITION factor. left numeric, modelling work , plot scatterplot. additional arguments can use, see function help customisation options.","code":"\nemmeans(Schroeder_fit, # add the model object  \n        ~ CONDITION) # What predictor do you want marginal means of? ##  CONDITION emmean lower.HPD upper.HPD\n##  0           3.01      2.06      3.91\n##  1           4.58      3.75      5.42\n## \n## Point estimate displayed: median \n## HPD interval probability: 0.95\nconditional_effects(Schroeder_fit)\nconditional_plot <- conditional_effects(Schroeder_fit)\n\nplot(conditional_plot, \n     plot = FALSE)[[1]] + #I don't know why you need this, but it doesn't work without\n  theme_classic() + \n  scale_y_continuous(limits = c(0, 10), breaks = seq(0, 10, 2)) + \n  scale_x_discrete(labels = c(\"Transcript\", \"Audio\")) + \n  labs(x = \"Speech Group\", y = \"Mean Hire Rating\")"},{"path":"introduction-to-bayesian-estimation.html","id":"model-checking","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.1.5 Model checking","text":"Finally, model checking procedure. already looked information Rhat, effect sample size, trace plots. suggests model fitted OK. also want check model reflects properties data. mean want exactly overfit data, follow similar pattern show model captures features data.Bayesian models generative, means fitted, can use sample values posterior make predictions . One key process called posterior predictive check takes model uses generate new samples. shows conditioned model expects.plot brms function facilitating . thick blue line data outcome. light blue lines 100 samples posterior show model expects outcome.example, OK job capturing pattern data bulk observed data follows generated curves. However, can see data quite flat compared predicted values. expect Gaussian distribution, model happily produce normal curves. model also happily expects values beyond range data scale bound 0 10. hugely common psychological research expect Gaussian distributions ordinal bound data. , model OK job, potentially improve focusing ordinal regression model can factor bounded nature measure raw measures.","code":"\npp_check(Schroeder_fit, \n         ndraws = 100) # How many draws from the posterior? Higher values means more lines"},{"path":"introduction-to-bayesian-estimation.html","id":"check-model-sensitivity-to-different-priors","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.1.5.1 Check model sensitivity to different priors","text":"final thing check model sensitive choice prior. justifiable informative prior key strength Bayesian statistics, important check model least two sets priors. example, compare model output default package priors user defined priors used along.code , omitted prior argument, fitting exact model using default package priors.run summary() function , can check intercept predictor coefficients see differ first model fitted. Ideally, provide us similar inferences, similar magnitude direction. never going exactly different priors, want conclusions robust choice prior use.make easier compare, can isolate key information model present side side. can see little difference intercept models. median similar, probability direction values 100%, 95% HDI ranges across similar values. user prior, coefficient little conservative, difference also small , showing results robust choice prior.","code":"\nSchroeder_fit2 <- brm(\n  formula = Schroeder_model1,\n  data = Schroeder_data, \n  family = gaussian(),\n  seed = 1908,\n  file = \"Models/Schroeder_model2\" #Save the model as a .rds file\n)\nsummary(Schroeder_fit2)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: Hire_Rating ~ CONDITION \n##    Data: Schroeder_data (Number of observations: 39) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept      2.90      0.52     1.89     3.93 1.00     3369     2457\n## CONDITION1     1.82      0.73     0.33     3.24 1.00     3578     2469\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     2.22      0.27     1.77     2.83 1.00     3446     2868\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"introduction-to-bayesian-estimation.html","id":"independent-activity-brandt-et-al.-2014","chapter":"10 Introduction to Bayesian Estimation","heading":"10.2.2 Independent activity (Brandt et al., 2014)","text":"independent activity, use data study (Brandt et al., 2014). aim Brandt et al. replicate relatively famous social psychology study (Banerjee et al., 2012) effect recalling unethical behaviour perception brightness.common language, unethical behaviour considered \"dark\", original authors designed priming experiment participants randomly allocated recall unethical behaviour ethical behaviour past. Participants completed series measures including perception bright testing room . Brandt et al. sceptical wanted replicate study see find similar results.Participants randomly allocated (\"ExpCond\") recall unethical behaviour (n = 49) ethical behaviour (n = 51). key outcome perception bright room (\"WellLitSca\"), 1 (bright ) 7 (bright). research question : recalling unethical behaviour lead people perceive room darker recall ethical behaviour?original study, found room perceived darker unethical condition compared ethical condition. means standard deviations Banerjee et al. reproduced Table 2 Brandt et al. might useful thinking priors later.Using understanding design, apply learnt guided example independent activity address research question. Following Bayesian modelling steps, fit least two models: one using default priors one using informative priors. Explore model results, think conclude research question, answer questions .coefficient positive negative? PositiveNegativeIs coefficient positive negative? PositiveNegativeCan confident direction coefficient?\n\nYes, 95% HDI excludes 0No, 95% HDI crosses 0\nCan confident direction coefficient?conclusion research question?\n\nRecalling unethical behaviour lead people perceive room darker.effect opposite direction confident manipulation effect.\nconclusion research question?results sensitive choice default user priors?\n\n, little difference parameters conclusions change.Yes, qualitative difference conclusions parameters change substantially.\nresults sensitive choice default user priors?normal model capture features data?\n\n, assuming normal distribution misses key features data.Yes, assuming normal distribution captures key features data.\nnormal model capture features data?experimental condition coefficient positive small value.experimental condition coefficient positive small value.Although coefficient positive, substantial overlap across 0.Although coefficient positive, substantial overlap across 0.Given uncertainty around coefficient, confident effect experimental condition perceived brightness.Given uncertainty around coefficient, confident effect experimental condition perceived brightness.results robust choice prior based means SDs original Banerjee et al. study. little difference user default priors.results robust choice prior based means SDs original Banerjee et al. study. little difference user default priors.contrast Schroeder Epley data ordinal data approximately normal, getting away characteristic ordinal distribution peaks integer. Really, need explore something like ordinal regression capture properties data. something covered Bayesian lectures activites, see bonus section showing ordinal model look like applied data.contrast Schroeder Epley data ordinal data approximately normal, getting away characteristic ordinal distribution peaks integer. Really, need explore something like ordinal regression capture properties data. something covered Bayesian lectures activites, see bonus section showing ordinal model look like applied data.can check attempt solutions bottom page. Remember based semi-random number generation, might variation precise values, qualitative conclusions consistent. want double check process accurate, can download saved models Github repository reproduce results way.","code":"\nBrandt_data <- read_csv(\"data/Brandt_unlit.csv\")\n\n# Recode to dummy coding \n# Turn to factor after recoding so we're working with groups\n\n# 0 = Ethical\n# 1 = Unethical\n\nBrandt_data <- Brandt_data %>% \n  mutate(ExpCond = as.factor(case_when(ExpCond == 1 ~ 0,\n                             ExpCond == -1 ~ 1)))"},{"path":"introduction-to-bayesian-estimation.html","id":"multipleregression","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3 Multiple Linear Regression","text":"","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"guided-example-heino-et-al.-2018","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3.1 Guided example (Heino et al., 2018)","text":"second guided example covered lecture, explore model included Heino et al. (2018) Bayesian data analysis tutorial. explored feasibility acceptability ”Let’s Move ” intervention increase physical activity 43 older adolescents.section, work multiple regression model following Bayesian modelling steps. less explanation simple linear regression section following processes, highlight anything new important consider two predictors.","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"identify-data-1","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3.1.1 Identify data","text":"Heino et al. (2018) randomised participants two groups (\"intervention\") control (0) intervention (1) arms (group sessions motivation self-regulation skills, teacher training). outcome measure autonomous motivation (\"value\") 1-5 scale, higher values meaning greater motivation. measured outcome baseline (0) six weeks (1; \"time\").research question : extent intervention affect autonomous motivation?Part tutorial discusses bigger multi-level model considering different scenarios, demonstration, just averaging scenarios get mean motivation. also convert intervention time factors work nicely plotting options later.","code":"\nHeino_data <- read_csv(\"data/Heino-2018.csv\") %>% \n  group_by(ID, intervention, time) %>% \n  summarise(value = mean(value, na.rm = TRUE)) %>% \n  mutate(intervention = factor(intervention, levels = c(0, 1)),\n         time = factor(time, levels = c(0, 1))) %>% \n  ungroup()"},{"path":"introduction-to-bayesian-estimation.html","id":"define-a-descriptive-model-1","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3.1.2 Define a descriptive model","text":"recommend reading article explain process detail. essentially outcome autonomous motivation (\"value\") want look interaction \"intervention\" \"time\". define fixed intercept model 1 + part. also technically multi-level model define random intercept participant ((1 | ID)) ensure recognise time within-subjects.default, R includes fixed intercept (1 + part) model, get results without adding model. However, people often include explicit model formula.","code":"\nHeino_model <- bf(value ~ 1 + time * intervention + (1 | ID))"},{"path":"introduction-to-bayesian-estimation.html","id":"specify-prior-probability-of-parameters-1","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3.1.3 Specify prior probability of parameters","text":"Compared simple linear regression, add predictors, number priors can set also increase. output , see can enter prior beta coefficients one specific predictors. also different options setting prior standard deviations since now group-level standard deviation random effect sigma distribution family since assuming outcome normal.Note, get warning missing data since multi-level model, just fewer observations conditions instead whole case removed.another place recommend reading original article information. discuss choices essentially settle wide weak priors coefficients say small effects likely allow larger effects. two standard deviation classes assigned relatively wide Cauchy priors.","code":"\nget_prior(Heino_model, data = Heino_data)## Warning: Rows containing NAs were excluded from the model.\nHeino_priors <- prior(normal(0, 5), class = \"b\") +\n  prior(cauchy(0, 1), class = \"sd\") +\n  prior(cauchy(0, 2), class = \"sigma\")"},{"path":"introduction-to-bayesian-estimation.html","id":"update-prior-to-posterior","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3.1.4 Update prior to posterior","text":"going longest section going fit brms model explore posterior.process relies sampling using MCMC, important set seed reproducibility, semi-random numbers consistent starting point. might take depending computer, get bunch output fitting model sampling MCMC chains. Remember, save models using file argument, easier load later. update model, must use file_refit argument change use file name.Now fitted model, look summary.model summary similar examples simple linear regression section, also new section group-level effects since added random intercept participants.Exploring coefficients, effects pretty small, largest effect 0.10 units. quite bit uncertainty , 95% credible intervals spanning negative positive effects, sample size quite small learn anything meaningful two groups.complicated models like , plotting going best friend understanding going . First , can check posteriors trace plots, although work model checking next section.posteriors quite wide spread 0 coefficients. trace plots suggest cause concern around convergence model.next key plot seeing probability direction priors superimposed.plot, can see wide priors . almost flat cover coefficients -10 10, posterior distributions peaking around 0. plots also show much can conclude results.Finally, can take closer look 95% HDI posterior distributions.Now zoom little without scale wide priors indication mass coefficient posteriors centered 0. need data make firm conclusions effectiveness intervention. data comes feasibility study, sample size pretty small mainly receptive participants intervention.","code":"\nHeino_fit <- brm(\n  formula = Heino_model,\n  data = Heino_data,\n  prior = Heino_priors,\n  family = gaussian(),\n  seed = 2108,\n  file = \"Models/Heino_model\"\n)\nsummary(Heino_fit)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: value ~ 1 + time * intervention + (1 | ID) \n##    Data: Heino_data (Number of observations: 68) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Group-Level Effects: \n## ~ID (Number of levels: 40) \n##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sd(Intercept)     0.71      0.10     0.54     0.92 1.00      907     1725\n## \n## Population-Level Effects: \n##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept               3.69      0.21     3.28     4.09 1.01      789     1511\n## time1                   0.09      0.15    -0.19     0.38 1.00     2442     2596\n## intervention1          -0.08      0.26    -0.59     0.44 1.01      761     1383\n## time1:intervention1     0.09      0.18    -0.28     0.43 1.00     2424     2565\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     0.33      0.05     0.25     0.44 1.00     1210     2101\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\nplot(Heino_fit)\nplot(p_direction(Heino_fit), \n     priors = TRUE) # plot the priors\nplot(bayestestR::hdi(Heino_fit)) # Specify to avoid clash with ggdist"},{"path":"introduction-to-bayesian-estimation.html","id":"calculating-and-plotting-conditional-effects-1","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3.1.4.1 Calculating and plotting conditional effects","text":"bonus extra since included Heino et al., can also use emmeans package calculate marginal effects posterior distribution. important little can learn breaking interaction , might come handy future.provides median value posterior combination time intervention. can see pretty clearly much going , little difference across estimates 95% credible intervals overlapping.Depending want express marginal means, can also use emmeans object calculate contrasts, expressing effects differences median posterior value group/condition. Just keep mind comparisons best address research question hypothesis. entered difference time intervention, might interested difference intervention time.Finally, can plot conditional effects normally good idea help reader understand results. object, used effects argument specify population level effect want plotting. omit effects argument, receive three plots example: one partial effect predictor one interaction.Like simple linear regression example, useful understanding, might quite appropriate inserting immediately report. save plot object, can add ggplot layers make easier reader understand. example, tidied axis names labels, changed scale reflect range outcome, added colour scheme differentiate two intervention groups.","code":"\n# Surround with brackets to both save and output\n(Heino_means <- emmeans(Heino_fit, # add the model object  \n        ~ time | intervention)) # We want to separate time by levels of intervention## intervention = 0:\n##  time emmean lower.HPD upper.HPD\n##  0      3.69      3.28      4.09\n##  1      3.78      3.39      4.16\n## \n## intervention = 1:\n##  time emmean lower.HPD upper.HPD\n##  0      3.60      3.28      3.92\n##  1      3.78      3.46      4.11\n## \n## Point estimate displayed: median \n## HPD interval probability: 0.95\ncontrast(Heino_means)## intervention = 0:\n##  contrast estimate lower.HPD upper.HPD\n##  0 effect  -0.0458   -0.1926    0.0926\n##  1 effect   0.0458   -0.0926    0.1926\n## \n## intervention = 1:\n##  contrast estimate lower.HPD upper.HPD\n##  0 effect  -0.0893   -0.1948    0.0143\n##  1 effect   0.0893   -0.0143    0.1948\n## \n## Point estimate displayed: median \n## HPD interval probability: 0.95\nconditional_effects(Heino_fit, \n                    effects = \"time:intervention\")\n# Save initial plot of the interaction\nconditional_plot <- conditional_effects(Heino_fit, \n                    effects = \"time:intervention\")\n\n# Call the plot and stop legend being included to prevent duplication later\nplot(conditional_plot, \n     plot = FALSE, \n     cat_args = list(show.legend = F))[[1]] + # No idea why, but doesn't work without the subsetting\n  theme_classic() + \n  scale_y_continuous(limits = c(1, 5), breaks = seq(1, 5, 1)) + \n  scale_x_discrete(labels = c(\"Baseline\", \"Six weeks\")) + \n  labs(x = \"Time\", y = \"Autonomous Motivation\") + \n  scale_color_viridis_d(option = \"D\", begin = 0.1, end = 0.7, \n                        name = \"Group\", labels = c(\"Control\", \"Intervention\")) # Add neater legend labels"},{"path":"introduction-to-bayesian-estimation.html","id":"model-fit-and-comparison","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3.1.4.2 Model fit and comparison","text":"Depending research question theoretical understanding variables working , might interested comparing different models assessing fit. something Heino et al. included, compare model one without interaction (lets pretend theoretically justified). Instead refitting whole new model, can update model change formula. settings like priors remain .First, can calculate \\(R^2\\) estimate proportion variance outcome predictors explain. brms specific function get model \\(R^2\\) 95% credible interval.can also compare two models side side. second model actually slightly higher \\(R^2\\) estimate, little choose two models.","code":"\n# Update model to a new formula\nHeino_fit2 <- update(Heino_fit, # Original brms model object \n                     formula. = ~ . - time:intervention) # tilda dot for the original formula, minus the interaction\n#R2 for first model object with interaction\nbayes_R2(Heino_fit)##     Estimate  Est.Error      Q2.5     Q97.5\n## R2 0.8025928 0.05267947 0.6740807 0.8766934\nR2_model1 <- as.data.frame(bayes_R2(Heino_fit))\nR2_model2 <- as.data.frame(bayes_R2(Heino_fit2))\n\nR2_table <- bind_rows(R2_model1, R2_model2)\nrownames(R2_table) <- c(\"Model with interaction\", \"Model without interaction\")\n\nknitr::kable(R2_table, \n             digits = 2,\n             row.names = TRUE,\n             col.names = c(\"R2 Estimate\", \"Estimated Error\", \"Lower 95% HDI\", \"Upper 95% HDI\"))"},{"path":"introduction-to-bayesian-estimation.html","id":"model-check","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3.1.5 Model check","text":"previous output, immediate causes concern. Trace plots showed good mixing chains, R-hat values higher 1.01, effective sample size values close thousands higher.final step, can look posterior predictive check make sure model capturing features data. model maps onto data quite well, samples largely following underlying data. still using metric models analyse ultimately ordinal data (despite calculating mean response), expected values go beyond range data (1-5), good enough caveat mind.scroll end Heino et al. article, demonstrate can fit ordinal model data average different situations.","code":"\npp_check(Heino_fit,\n         ndraws = 100) # 100 draws from the model"},{"path":"introduction-to-bayesian-estimation.html","id":"check-model-sensitivity-to-different-priors-1","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3.1.5.1 Check model sensitivity to different priors","text":"final thing check model sensitive choice prior. example, compare model output default package priors user defined priors Heino et al.code , omitted prior argument, fitting exact model using default package priors. time just update model, need refit .run summary() function , can check intercept predictor coefficients see differ first model fitted. Ideally, provide us similar inferences, similar magnitude direction. never going exactly different priors, want conclusions robust choice prior use.make easier compare, can isolate key information model present side side. can see little difference intercept coefficients models. suggests results robust two choices prior.","code":"\nHeino_fit3 <- brm(\n  formula = Heino_model,\n  data = Heino_data,\n  family = gaussian(),\n  seed = 2108,\n  file = \"Models/Heino_model3\"\n)\nsummary(Heino_fit3)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: value ~ 1 + time * intervention + (1 | ID) \n##    Data: Heino_data (Number of observations: 68) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Group-Level Effects: \n## ~ID (Number of levels: 40) \n##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sd(Intercept)     0.71      0.10     0.53     0.94 1.00      896     1615\n## \n## Population-Level Effects: \n##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept               3.68      0.21     3.27     4.08 1.00      916     1677\n## time1                   0.09      0.15    -0.19     0.39 1.00     2541     2786\n## intervention1          -0.07      0.27    -0.58     0.46 1.00      753     1196\n## time1:intervention1     0.09      0.19    -0.29     0.44 1.00     2384     2585\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     0.33      0.05     0.25     0.45 1.00     1003     1602\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"introduction-to-bayesian-estimation.html","id":"independent-activity-coleman-et-al.-2019","chapter":"10 Introduction to Bayesian Estimation","heading":"10.3.2 Independent activity (Coleman et al., 2019)","text":"independent activity, use data study Coleman et al. (2019). Coleman et al. contains two studies investigating religious mystical experiences. One study focused undergraduates second study focused experienced meditators part unique religious group.data set contains range variables used full model paper. going focus small part exercise, feel free explore developing full model used study 1. key variables :\"Age\" - Measured years\"Age\" - Measured years\"Gender\" - 0 = male; 1 = female\"Gender\" - 0 = male; 1 = female\"Week_med\" - Ordinal measure often people meditate per week, higher values meaning often\"Week_med\" - Ordinal measure often people meditate per week, higher values meaning often\"Time_session\" - Ordinal measure long people meditate per session, higher values meaning longer\"Time_session\" - Ordinal measure long people meditate per session, higher values meaning longer\"Absorption_SUM\" - Sum score Modified Tellegen Absorption scale, higher values meaning greater trait levels imaginative engagement\"Absorption_SUM\" - Sum score Modified Tellegen Absorption scale, higher values meaning greater trait levels imaginative engagement\"EQ_SUM\" - Sum score Empathizing Quotient short form, higher values meaning greater theory mind ability\"EQ_SUM\" - Sum score Empathizing Quotient short form, higher values meaning greater theory mind ability\"Mscale_SUM\" - Sum score Hood M-scale, higher values meaning self-reported mystical experiences\"Mscale_SUM\" - Sum score Hood M-scale, higher values meaning self-reported mystical experiencesPrevious studies explored components separately mainly undergraduates, Coleman et al. took opportunity explore unique sample highly committed religious group. final model included seven variables, example, just focus absorption (\"Absorption_SUM\") theory mind (\"EQ_SUM\") main contributors, variables covariates.follow link Coleman et al. , can see results study 2 focused undergraduate students. study presented second, can use example develop understanding measures priors. Keep mind partial effects since predictors model, key parameters apart interaction. interaction statistically significant, retained model reported final table.research question : absorption (\"Absorption_SUM\") mentalizing (\"EQ_SUM\") related mystical experiences (\"Mscale_SUM\") outcome? interaction theoretical interest , focus interaction first.Using understanding design, apply learnt guided example independent activity address research question. Following Bayesian modelling steps, fit least three models: one using default priors, one using informative priors, one removing interaction term. Explore model results, think conclude research question, answer questions .coefficient absorption positive negative? PositiveNegativeIs coefficient absorption positive negative? PositiveNegativeIs coefficient theory mind positive negative? PositiveNegativeIs coefficient theory mind positive negative? PositiveNegativeCan confident direction individual predictors?\n\n, 95% HDI coefficients contain 0.95% HDI absorption contains 0, theory mind positive excludes 0.95% HDI theory mind contains 0, absorption positive excludes 0.Yes, individual predictors positive 95% HDI excludes 0.\nCan confident direction individual predictors?can interpret interaction?\n\nclear interaction.lower values theory mind, slope becomes positive.lower values theory mind, slope becomes negative.\ncan interpret interaction?Hint:  need look conditional effects plot see one predictor moderates effect predictor.Comparing models without interaction term, retain?\n\nmodel interaction term clearly better fit.model without interaction term clearly better fit.little difference two models, retain interaction theoretical interest.\nresults sensitive choice default user priors?\n\nYes, qualitative difference conclusions parameters change substantially., almost difference parameters conclusions change.\npartial effect absorption positive predictor mystical experiences.partial effect absorption positive predictor mystical experiences.partial effect theory mind positive predictor mystical experiences.partial effect theory mind positive predictor mystical experiences.partial effects, positive 95% HDI clearly excludes zero. Particularly absorption, little uncertainty marginally stronger effect compared theory mind.partial effects, positive 95% HDI clearly excludes zero. Particularly absorption, little uncertainty marginally stronger effect compared theory mind.complicated one accept saying clear interaction. difficult interpret interaction two continuous predictors relying conditional effects plot. slope mystical experiences absorption positive lower values theory mind, highest density intervals overlap particularly higher values absorption.complicated one accept saying clear interaction. difficult interpret interaction two continuous predictors relying conditional effects plot. slope mystical experiences absorption positive lower values theory mind, highest density intervals overlap particularly higher values absorption.key concept interaction theoretical interest. little difference two models - least \\(R^2\\) estimates - interested interaction slightly larger estimate.key concept interaction theoretical interest. little difference two models - least \\(R^2\\) estimates - interested interaction slightly larger estimate.lot data three predictors, choice prior little impact. posterior entirely dominated data get variation second third decimal place.lot data three predictors, choice prior little impact. posterior entirely dominated data get variation second third decimal place.can check attempt solutions bottom page. Remember based semi-random number generation, might variation precise values, qualitative conclusions consistent. want double check process accurate, can download saved models Github repository reproduce results way.","code":"\nColeman_data <- read_csv(\"data/Coleman_2019.csv\") %>% \n  mutate(Absorption_SUM = Absorption_SUM - mean(Absorption_SUM), # Mean center the predictors\n         EQ_SUM = EQ_SUM - mean(EQ_SUM))"},{"path":"introduction-to-bayesian-estimation.html","id":"summary-1","chapter":"10 Introduction to Bayesian Estimation","heading":"10.4 Summary","text":"chapter, learnt Bayesian modelling process. works 1) identifying data, 2) defining descriptive model, 3) specifying prior probability distributions parameters, 4) updating priors posterior probability distributions, 5) model checking. flexible approach data analysis control outcome, predictors, distribution family. also scales well work single predictors way complex multi-level models.Modelling Bayesian statistics powerful encourages thoughtful approach data analysis. Just keep mind, can still done mindlessly silver bullet problems data analysis psychology. though, process setting priors, model checking, exploring uncertainty reinforces good thoughtful habits.","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"taking-this-further","chapter":"10 Introduction to Bayesian Estimation","heading":"10.5 Taking this further","text":"content chapter scales well different use cases, hopefully can apply learnt different types outcome predictors. suggested reading expand knowledge techniques, see following list resources.Reporting guidelinesSchoot et al. (2021) provide primer Bayesian modelling, also outline reporting guidelines information check include.Schoot et al. (2021) provide primer Bayesian modelling, also outline reporting guidelines information check include.Kruschke (2021) just focuses reporting guidelines Bayesian models.Kruschke (2021) just focuses reporting guidelines Bayesian models.TextbooksKruschke (2015) walks logic statistics behind Bayesian models. use brms package, might like refer translation Kurz.Kruschke (2015) walks logic statistics behind Bayesian models. use brms package, might like refer translation Kurz.McElreath (2020) personal favourite textbook outlining Bayesian approach modelling. uses teaching-focused R package work modelling mechanisms great YouTube series posts supporting lectures every year.McElreath (2020) personal favourite textbook outlining Bayesian approach modelling. uses teaching-focused R package work modelling mechanisms great YouTube series posts supporting lectures every year.Additional distribution familiesBürkner & Vuorre (2019) demonstrates ordinal regression models ordinal data like individual Likert responses.Bürkner & Vuorre (2019) demonstrates ordinal regression models ordinal data like individual Likert responses.Heiss (2021) demonstrates beta regression can used model proportion data.Heiss (2021) demonstrates beta regression can used model proportion data.Winter & Bürkner (2021) demonstrates Poisson regression model count data using brms.Winter & Bürkner (2021) demonstrates Poisson regression model count data using brms.Comparing Bayesian frequentist modellingFlores et al. (2022) compares results receive Bayesian frequentist multi-level models","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"independent-activity-solutions-1","chapter":"10 Introduction to Bayesian Estimation","heading":"10.6 Independent activity solutions","text":"","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"Brandt-solution","chapter":"10 Introduction to Bayesian Estimation","heading":"10.6.1 Brandt et al. (2014)","text":"minor variation values output since based semi-random numbers, particularly priors different . important thing internally consistent output process. conclusions answers questions independent activity , can see output check answers .Step 1. Identify data relevant research questionTo follow modelling process, read data Brandt et al.Step 2. Define descriptive modelFor model, working simple linear regression. one outcome welllit one categorical predictor ExpCond. can also check priors can specify:Step 3. Specify prior probability distribution model parametersFor intercept, know scale ranges 1 7, reference group ethical priming, mean (SD) Banerjee et al. 5.3 (0.97). means can expect intercept somewhat middle scale, tweaking, use prior :coefficient, brightness rating 0.59 units lower unethical priming group compared ethical priming group. quite small effect whether favour effect one direction depends convinced manipulation. set prior normal distribution 0 SD 0.5. means 0 likely value mass -1 1 consider effects positive negative direction.Step 4. Update prior posterior distributionFor first model, just use default priors minimal influence parameters.summarise first model, effects seemingly opposite direction. default prior model, unethical group 0.21 units higher posterior median ethical group. means unethical group perceived room brighter, lot uncertainty mass posterior spanning across negative positive values.Now, can fit second model using informed priors.Using informed priors, get similar results. intercept estimates almost identical coefficient estimates marginally smaller default priors. means inferences robust choice priors. Apart compare estimates model, focus second model informed priors.Step 5. Check model dataOur model diagnostics looked respectable. Rhat values 1 ESS thousands. compare two models, get similar estimates default informed priors.However, posterior predictive check, good example assumed distribution capture features underlying data. Whereas Schroeder Epley approximated normal data, getting away characteristically ordinal. purposes self-test questions, can persist normal model original authors replicators used, include bonus section looks like ordinal model.","code":"\nBrandt_model <- bf(welllit ~ ExpCond)\n\nget_prior(Brandt_model,\n          data = Brandt_data)\nBrandt_priors <- set_prior(\"normal(4, 1.2)\", class = \"Intercept\") + \n  set_prior(\"normal(0, 0.5)\", class = \"b\") + \n  set_prior(\"exponential(1)\", class = \"sigma\")\nBrandt_fit1 <- brm(\n  formula = Brandt_model,\n  data = Brandt_data,\n  family = gaussian(),\n  seed = 80323,\n  file = \"Models/Brandt_model1\"\n)\nsummary(Brandt_fit1)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: welllit ~ ExpCond \n##    Data: Brandt_data (Number of observations: 100) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept     5.16      0.18     4.79     5.52 1.00     4095     3013\n## ExpCond1      0.21      0.25    -0.29     0.69 1.00     3879     3192\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     1.29      0.10     1.11     1.49 1.00     3722     2380\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\nBrandt_fit2 <- brm(\n  formula = Brandt_model,\n  data = Brandt_data,\n  family = gaussian(),\n  prior = Brandt_priors,\n  sample_prior = TRUE,\n  seed = 80323,\n  file = \"Models/Brandt_model2\"\n)\nsummary(Brandt_fit2)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: welllit ~ ExpCond \n##    Data: Brandt_data (Number of observations: 100) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept     5.16      0.17     4.84     5.48 1.00     4136     2989\n## ExpCond1      0.17      0.22    -0.26     0.61 1.00     4246     2923\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma     1.28      0.09     1.12     1.48 1.00     3232     2918\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\nplot(p_direction(Brandt_fit2), \n     priors = TRUE) \nplot(bayestestR::hdi(Brandt_fit2)) # Specify package to avoid clash with ggdist\nmodel1 <- describe_posterior(Brandt_fit1) %>% \n  dplyr::mutate(Model = \"User prior\") %>% \n  dplyr::select(Model, Parameter, Median, CI_low, CI_high) \n\nmodel2 <- describe_posterior(Brandt_fit2) %>% \n  dplyr::mutate(Model = \"Default prior\") %>% \n  dplyr::select(Model, Parameter, Median, CI_low, CI_high) \n\nbind_rows(model1, model2) %>% \n  arrange(desc(Parameter)) %>% \n  knitr::kable(digits = 2,\n               col.names = c(\"Model\", \"Parameter\", \"Median Estimate\", \"Lower 95% HDI\", \"Upper 95% HDI\"))\npp_check(Brandt_fit2,\n         ndraws = 100)"},{"path":"introduction-to-bayesian-estimation.html","id":"Brandt-bonus","chapter":"10 Introduction to Bayesian Estimation","heading":"10.6.1.1 Bonus: Ordinal model of Brandt et al.","text":"Instead assuming Gaussian distribution, can fit cumulative probit model, assuming normally distributed latent variable behind ordinal item. demonstration, just use default priors see Bürkner & Vuorre (2019) full discussion Bayesian ordinal regression models. Almost arguments identical previous models, apart one feature.regular models, avoided many fitting problems. model though, get warnings leave default settings. One \"Warning: X divergent transitions warmup. Increasing adapt_delta 0.8 may help\". means sampling posterior, can divergent transitions cause bias. Increasing delta 0.9 0.99 (must smaller 1) slows fitting process, often helps avoid issues. least computer, increasing delta 0.99 fixed warnings.Now model, can get summary like . might look little different longer just one intercept one coefficient model. scale 7 response options, cumulative probit model, get successive thresholds response options.primary estimate interest coefficient experimental condition. categorical predictor, represents shift latent outcome ethical (0) unethical (1). expressed standard deviations, unethical group lead 0.16 increase brightness rating, 95% credible interval ranges -0.26 0.58, meaning lot uncertainty conclude experimental condition led difference brightness ratings.model, can look posterior predictive check see represents data better. Compared normal model, much better capturing ordinal features draw posterior.model summary, can think model looks like visually. can get conditional effects response options experimental condition. estimated probabilities 7 response options little support difference two groups. pattern responses similar groups. means make similar conclusion normal distribution model, respects underlying distribution better.","code":"\nBrandt_fit3 <- brm(\n  formula = Brandt_model,\n  data = Brandt_data,\n  family = cumulative(\"probit\"), # cumulative probit model for ordinal values\n  seed = 80323,\n  file = \"Models/Brandt_model3\",\n  control = list(adapt_delta = 0.99) # Change from default to decrease divergent transitions \n)\nsummary(Brandt_fit3)##  Family: cumulative \n##   Links: mu = probit; disc = identity \n## Formula: welllit ~ ExpCond \n##    Data: Brandt_data (Number of observations: 100) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## Intercept[1]    -2.55      0.45    -3.51    -1.79 1.00     2415     2405\n## Intercept[2]    -2.26      0.38    -3.10    -1.60 1.00     3239     2753\n## Intercept[3]    -1.06      0.18    -1.42    -0.71 1.00     4224     2850\n## Intercept[4]    -0.65      0.17    -1.00    -0.33 1.00     3871     3024\n## Intercept[5]     0.09      0.16    -0.24     0.40 1.00     3756     2812\n## Intercept[6]     1.18      0.19     0.82     1.55 1.00     3825     3134\n## ExpCond1         0.16      0.21    -0.26     0.58 1.00     3555     2854\n## \n## Family Specific Parameters: \n##      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## disc     1.00      0.00     1.00     1.00   NA       NA       NA\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\npp_check(Brandt_fit3, \n         ndraws = 100)\nconditional_effects(x = Brandt_fit3, \n                    effects = \"ExpCond\", \n                    categorical = TRUE)"},{"path":"introduction-to-bayesian-estimation.html","id":"Coleman-solution","chapter":"10 Introduction to Bayesian Estimation","heading":"10.6.2 Coleman et al. (2019)","text":"minor variation values output since based semi-random numbers, particularly priors different . important thing internally consistent output process. conclusions answers questions independent activity , can see output check answers .Step 1. Identify data relevant research questionTo follow modelling process, read data Coleman et al.Step 2. Define descriptive modelFor demonstration, going predict mystical experiences theory mind absorption, interaction second model. interaction primary focus, fit model first, update see impact removing interaction.Step 3. Specify prior probability distribution model parametersFor intercept, know mystical experiences scale ranges 40 160. intercept Coleman et al. study two 109 95% confidence interval ranging 104 113. playing around prior plots, normal distribution 109 (SD = 17) peak study two intercept likely value, tails cut around minimum maximum scale range.coefficients, variables centered, can think unit change outcome. largest predictor 0.42 units largest side 95% confidence interval 0.54. Therefore, can set prior 0 peak express smaller effects likely, accept larger values direction SD 1.Finally, sigma, model SD reported Coleman et al., keep default settings avoid much influence. can plot options piece together patchwork.can enter values informed priors.Step 4. Update prior posterior distributionNow model priors, can fit first model including interaction.Lets look first summary model output.population level effects relatively consistent priors. intercept slightly higher 120 individual coefficients positive predictors mystical experiences. partial effects predictor, expect higher mystical experiences higher values theory mind absorption. clearly positive predictors 95% HDI near zero.interaction, always hard interpret single coefficient. return interpreting plot conditional effects soon.now, lets explore plots model coefficients. First, trace plots look well mixed can see overview posterior distributions.Looking probability direction plots prior superimposed, can see decent sized sample produces narrow posterior compared prior. open effects either direction, data dominates produce consistently positive individual predictors.can look plotting distribution 95% HDI. can see 95% HDI clearly excludes 0 absorption partial predictor less uncertainty.Next, can finally made sense interaction theory mind absorption. two continuous predictors interaction, get three plots. get partial effect predictor isolation, get moderating effect one predictor , want help interpret interaction.focus interaction, since included absorption model first theory mind second, get relationship mystical experiences absorption different values theory mind. known simple slopes analysis hold effect moderator constant different values: 1 SD mean, mean, 1 SD mean. shows overlap relationships, relationship stronger lower values theory mind. slope positive theory mind 1 SD mean 1 SD mean.bonus extra expected know , Kurz demonstrated slightly different way plotting continuous interaction. key differences requesting spaghetti plot drawing posterior. Unlike solid bands default, samples posterior generates regression lines mystical experiences theory mind level simple slopes absorption. slope gets ever slightly weaker (flatter) higher values absorption. additional options tidy things show underlying data points.Step 5. Check model dataOur model diagnostics looked fine. R-hat values 1, effective sample size values thousands, trace plots looked well mixed. Finally, lets look posterior predictive check.upward part curve far , clearly something capturing upper values outcome. probably another case model going beyond limits data sum M scale maximum value 160. telling model apply normal distribution, happily accept values towards 200 beyond scale. good enough purposes , explore whether assuming different distribution family fits outcome better.","code":"\n# Predicting mystical experiences from the interaction between theory of mind and absorption\n\nColeman_model <- bf(Mscale_SUM ~ Absorption_SUM * EQ_SUM) \n# What priors can we specify? \nget_prior(Coleman_model, data = Coleman_data)\nColeman_priors <- prior(\"normal(0, 1)\", class = \"b\") + \n  prior(\"normal(109, 17)\", class = \"Intercept\")\nColeman_fit <- brm(\n  formula = Coleman_model,\n  data = Coleman_data,\n  family = gaussian(),\n  prior = Coleman_priors,\n  seed = 200323,\n  file = \"Models/Coleman_model1\"\n)\nsummary(Coleman_fit)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: Mscale_SUM ~ Absorption_SUM * EQ_SUM \n##    Data: Coleman_data (Number of observations: 269) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\n## Intercept               120.27      1.50   117.29   123.19 1.00     4951\n## Absorption_SUM            0.60      0.07     0.47     0.73 1.00     3930\n## EQ_SUM                    0.54      0.18     0.20     0.88 1.00     4204\n## Absorption_SUM:EQ_SUM    -0.01      0.01    -0.03     0.00 1.00     4631\n##                       Tail_ESS\n## Intercept                 3078\n## Absorption_SUM            2731\n## EQ_SUM                    2999\n## Absorption_SUM:EQ_SUM     3126\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma    22.97      1.03    21.12    25.09 1.00     4509     2687\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1).\nplot(Coleman_fit)\nplot(p_direction(Coleman_fit), \n     priors = TRUE) # plot the priors\nplot(bayestestR::hdi(Coleman_fit)) # to avoid clashing with ggdist\nconditional_effects(Coleman_fit)\nColeman_conditional <- conditional_effects(Coleman_fit,\n                    effects = \"Absorption_SUM:EQ_SUM\", # Restrict to \n                    spaghetti = T, # Plot individual draws instead of point estimates\n                    ndraws = 150) # How many draws from the posterior? \n\nplot(Coleman_conditional, \n     plot = FALSE, \n     cat_args = list(show.legend = F),\n     points = T,\n     point_args = c(alpha = 0.5, size = 1), \n     mean = T)[[1]] + \n  theme_classic() + \n  labs(y = \"Mystical Experiences\", x = \"Absorption\")\npp_check(Coleman_fit, \n         ndraws = 100) # 100 draws from the model"},{"path":"introduction-to-bayesian-estimation.html","id":"model-fit-and-prior-sensitivity","chapter":"10 Introduction to Bayesian Estimation","heading":"10.6.2.0.1 Model fit and prior sensitivity","text":"final thing check model fit sensitive results choice priors. can explore impact removing interaction demonstrate process, note study theoretical interest include focus interaction.First, can calculate \\(R^2\\) estimate proportion variance outcome predictors explain.can also compare two models side side. model interaction highest \\(R^2\\) estimate, little difference much variance explain. stick interaction model since theoretical interest.check sensitivity results different priors, fit one final model removing user priors.Using informed priors, get similar results. sample size relatively large three predictors (including interaction), data pretty much overwhelm sensible choices priors.compare models side side, can summarise key parameters. can see, differences second third decimal place.","code":"\n# Update model to a new formula\nColeman_fit2 <- update(Coleman_fit, # Original brms model object \n                     formula. = ~ . - Absorption_SUM:EQ_SUM) # tilda dot for the original formula, minus the interaction\n#R2 for first model object with interaction\nbayes_R2(Coleman_fit)##     Estimate  Est.Error      Q2.5     Q97.5\n## R2 0.3303394 0.03797409 0.2499044 0.3996068\nColeman_fit3 <- brm(\n  formula = Coleman_model,\n  data = Coleman_data,\n  family = gaussian(),\n  seed = 200323,\n  file = \"Models/Coleman_model3\"\n)\nsummary(Coleman_fit3)##  Family: gaussian \n##   Links: mu = identity; sigma = identity \n## Formula: Mscale_SUM ~ Absorption_SUM * EQ_SUM \n##    Data: Coleman_data (Number of observations: 269) \n##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n##          total post-warmup draws = 4000\n## \n## Population-Level Effects: \n##                       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\n## Intercept               120.39      1.48   117.47   123.32 1.00     4613\n## Absorption_SUM            0.60      0.07     0.48     0.74 1.00     4105\n## EQ_SUM                    0.55      0.18     0.18     0.89 1.00     4267\n## Absorption_SUM:EQ_SUM    -0.01      0.01    -0.03     0.00 1.00     4727\n##                       Tail_ESS\n## Intercept                 2900\n## Absorption_SUM            2961\n## EQ_SUM                    3243\n## Absorption_SUM:EQ_SUM     3064\n## \n## Family Specific Parameters: \n##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n## sigma    22.98      1.04    21.05    25.07 1.00     4343     3088\n## \n## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n## and Tail_ESS are effective sample size measures, and Rhat is the potential\n## scale reduction factor on split chains (at convergence, Rhat = 1)."},{"path":"installing-r.html","id":"installing-r","chapter":"A Installing R","heading":"A Installing R","text":"Installing R RStudio usually straightforward. sections explain helpful YouTube video .","code":""},{"path":"installing-r.html","id":"installing-base-r","chapter":"A Installing R","heading":"A.1 Installing Base R","text":"Install base R. Choose download link operating system (Linux, Mac OS X, Windows).Mac, install latest release newest R-x.x.x.pkg link (legacy version older operating system). install R, also install XQuartz able use visualisation packages.installing Windows version, choose \"base\" subdirectory click download link top page. install R, also install RTools; use \"recommended\" version highlighted near top list.using Linux, choose specific operating system follow installation instructions.","code":""},{"path":"installing-r.html","id":"installing-rstudio","chapter":"A Installing R","heading":"A.2 Installing RStudio","text":"Go rstudio.com download RStudio Desktop (Open Source License) version operating system list titled Installers Supported Platforms.","code":""},{"path":"installing-r.html","id":"rstudio-settings","chapter":"A Installing R","heading":"A.3 RStudio Settings","text":"settings fix immediately updating RStudio. Go Global Options... Tools menu (⌘,), General tab, uncheck box says Restore .RData workspace startup. keep things around workspace, things get messy, unexpected things happen. always start clear workspace. also means never want save workspace exit, set Never. thing want save scripts.may also want change appearance code. Different fonts themes can sometimes help visual difficulties dyslexia.\nFigure .1: RStudio General Appearance settings\nmay also want change settings Code tab. Foe example, Lisa prefers two spaces instead tabs code likes able see whitespace characters. matter personal preference.\nFigure .2: RStudio Code settings\n","code":""},{"path":"installing-r.html","id":"installing-latex","chapter":"A Installing R","heading":"A.4 Installing LaTeX","text":"can install LaTeX typesetting system produce PDF reports RStudio. Without additional installation, able produce reports HTML PDF. course require make PDFs. generate PDF reports, additionally need install tinytex (Xie, 2022) run following code:","code":"\ntinytex::install_tinytex()"},{"path":"installing-r.html","id":"installing-the-brms-package","chapter":"A Installing R","heading":"A.5 Installing the brms package","text":"chapter 10, use brms fit Bayesian regression models. Behind scenes, package uses programming language called Stan requires C++ compiler. Unlike packages, just use install.packages() function install , steps follow.best place start referring FAQs package Github page.First, Windows computer, install Rtools. Mac, install Xcode.program relevant computer, can install brms usual:","code":"\ninstall.packages(\"brms\")"},{"path":"Frequentist-Equivalence.html","id":"Frequentist-Equivalence","chapter":"B Frequentist Equivalence Testing","heading":"B Frequentist Equivalence Testing","text":"Link Lakens et al. papersLink Lakens et al. papersRepeat examples ROPE show differentRepeat examples ROPE show differentShow plotShow plot","code":""},{"path":"conventions.html","id":"conventions","chapter":"C Conventions","heading":"C Conventions","text":"book use following conventions:Generic code: list(number = 1, letter = \"\")Highlighted code: dplyr::slice_max()File paths: data/sales.csvR Packages: tidyverseBacktick functions: paste()Functions: paste()Strings: \"psyTeachR\"Numbers: 100, 3.14Logical values: TRUE, FALSEGlossary items: ordinalCitations: Wickham (2022)Internal links: Chapter ??External links: R Data ScienceMenu/interface options: New File...","code":""},{"path":"conventions.html","id":"webexercises","chapter":"C Conventions","heading":"C.1 Webexercises","text":"See webexercises details use materials.Type integer: going learn lot: TRUEFALSEWhat p-value?\n\nprobability null hypothesis truethe probability observed (extreme) data, assumption null-hypothesis truethe probability making error conclusion\nfound hidden text!","code":"\nprint(\"You found some hidden code!\")## [1] \"You found some hidden code!\""},{"path":"conventions.html","id":"alert-boxes","chapter":"C Conventions","heading":"C.2 Alert boxes","text":"Informational asides.Notes warn something.Notes things cause serious errors.Try .","code":""},{"path":"conventions.html","id":"code-chunks","chapter":"C Conventions","heading":"C.3 Code Chunks","text":"","code":"\n# code chunks\npaste(\"Applied\", \"Data\", \"Skills\", 1, sep = \" \")## [1] \"Applied Data Skills 1\"```{r setup, message = FALSE}\n# code chunks with visible r headers\nlibrary(tidyverse)```"},{"path":"conventions.html","id":"glossary","chapter":"C Conventions","heading":"C.4 Glossary","text":"","code":""},{"path":"glossary-1.html","id":"glossary-1","chapter":"D Glossary","heading":"D Glossary","text":"can use glossary() function automatically link term psyTeachR glossary make project-specific glossary.create link glossary include tooltip short definition hover term. Use following syntax inline r: glossary(\"word\"). example, common data types integer, double, character.need link definition, using different form word, add display version second argument (display). can also override automatic short definition providing third argument (def). Add argument link = FALSE just want hover definition link psyTeachR glossary.[1] \"Data Types\"can add glossary table end chapter following code. creates table terms used chapter previous glossary_table() function. uses kableExtra(), use code chunk, set results='asis'.want contribute glossary, fork github project, add terms submit pull request, suggest new term issues page.","code":"\nglossary(\"data type\", \n         display = \"Data Types\", \n         def = \"My custom definition of data types\", \n         link = FALSE)```{r, echo=FALSE, results='asis'}\nglossary_table()```"},{"path":"license.html","id":"license","chapter":"License","heading":"License","text":"book licensed Creative Commons Attribution-ShareAlike 4.0 International License (CC--SA 4.0). free share adapt book. must give appropriate credit (psyteachr-template?), provide link license, indicate changes made. adapt material, must distribute contributions license original.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
