[{"path":"index.html","id":"overview","chapter":"Overview","heading":"Overview","text":"","code":""},{"path":"introduction-to-linear-regression-1.html","id":"introduction-to-linear-regression-1","chapter":"1 Introduction to Linear Regression 1","heading":"1 Introduction to Linear Regression 1","text":"","code":""},{"path":"introduction-to-linear-regression-2.html","id":"introduction-to-linear-regression-2","chapter":"2 Introduction to Linear Regression 2","heading":"2 Introduction to Linear Regression 2","text":"","code":""},{"path":"introduction-to-generalised-linear-models-1.html","id":"introduction-to-generalised-linear-models-1","chapter":"3 Introduction to Generalised Linear Models 1","heading":"3 Introduction to Generalised Linear Models 1","text":"","code":""},{"path":"introduction-to-generalised-linear-models-2.html","id":"introduction-to-generalised-linear-models-2","chapter":"4 Introduction to Generalised Linear Models 2","heading":"4 Introduction to Generalised Linear Models 2","text":"","code":""},{"path":"introduction-to-linear-mixed-effects-models.html","id":"introduction-to-linear-mixed-effects-models","chapter":"5 Introduction to Linear Mixed Effects Models","heading":"5 Introduction to Linear Mixed Effects Models","text":"","code":""},{"path":"introduction-to-percentile-bootstrap.html","id":"introduction-to-percentile-bootstrap","chapter":"6 Introduction to Percentile Bootstrap","heading":"6 Introduction to Percentile Bootstrap","text":"","code":""},{"path":"graphical-representations.html","id":"graphical-representations","chapter":"7 Graphical Representations","heading":"7 Graphical Representations","text":"","code":""},{"path":"myths-and-fallacies.html","id":"myths-and-fallacies","chapter":"8 Myths and Fallacies","heading":"8 Myths and Fallacies","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"introduction-to-bayesian-hypothesis-testing","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9 Introduction to Bayesian Hypothesis Testing","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"learning-objectives","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.1 Learning objectives","text":"blah blah blah.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"bayes-logic","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.2 The Logic Behind Bayesian Inference","text":"demonstrate logic behind Bayesian inference, play around shiny app Wagenmakers (2015). text walks app provides exercises explore , use explore defining prior distribution seeing posterior updates data.example based estimating proportion yellow candies bag different coloured candies. see yellow candy, logged 1. see non-yellow candy, logged 0. want know proportion candies yellow.handy demonstration logic behind Bayesian inference simplest application. Behind scenes, calculate values directly distributions simple one parameter. later examples lesson 10, focus complicated models require sampling posterior.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"step-1---pick-your-prior","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.2.1 Step 1 - Pick your prior","text":"First, define prior expectations proportion yellow candies. dichotomous outcome like (yellow yellow), can model prior beta distribution (define). two parameters set: b.Explore changing parameters impact distribution, observations orient :Setting 1 create flat prior: proportion possible.Setting 1 create flat prior: proportion possible.Using number centers distribution 0.5, increasing numbers showing greater certainty (higher peak).Using number centers distribution 0.5, increasing numbers showing greater certainty (higher peak).parameter < b, proportions less 0.5 likely.parameter < b, proportions less 0.5 likely.parameter b > , proportions higher 0.5 likely.parameter b > , proportions higher 0.5 likely.playing around, proportion yellow candies think likely? certain value accepting data?","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"step-2---update-to-the-posterior","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.2.2 Step 2 - Update to the posterior","text":"Now prior, time collect data update posterior. lecture, play around practical demonstration seeing many candies yellow, set prior entering value b, see data tell us. two boxes entering data: number yellows observe, number non-yellows observe.trying , explore changing prior data see affects posterior distribution. inspiration key observations:Setting uninformative (1,1) weak prior (2, 2) 0.5, posterior dominated data. example, imagine observed 5 yellows 10 non-yellows. posterior peaks around 0.30 plausibly ranges 0.2 0.6. Changing data completely changes posterior show prior little influence. change number yellows non-yellows, posterior updates dramatically.Setting uninformative (1,1) weak prior (2, 2) 0.5, posterior dominated data. example, imagine observed 5 yellows 10 non-yellows. posterior peaks around 0.30 plausibly ranges 0.2 0.6. Changing data completely changes posterior show prior little influence. change number yellows non-yellows, posterior updates dramatically.Now set strong prior (20, 20) 0.5 5 yellows 10 non-yellows. Despite observed data showing proportion 0.33, peak posterior distribution slightly higher 0.4. posterior compromise prior likelihood, stronger prior means need data change beliefs. example, imagine 10 times data 50 yellows 100 non-yellows. Now, greater density 0.3 0.4, show posterior now convinced proportion yellows.Now set strong prior (20, 20) 0.5 5 yellows 10 non-yellows. Despite observed data showing proportion 0.33, peak posterior distribution slightly higher 0.4. posterior compromise prior likelihood, stronger prior means need data change beliefs. example, imagine 10 times data 50 yellows 100 non-yellows. Now, greater density 0.3 0.4, show posterior now convinced proportion yellows.demonstration, note two curves prior posterior, without likelihood. prior posterior come distribution family, known conjugate prior (define), beta distribution one simplest. simply modelling proportion successes failures (yellows vs non-yellows).section 4, can also explore Bayes factors applied scenario, working much shift belief favour alternative hypothesis compared null (, proportion exactly 0.5). point lecture, explored Bayes factors yet, continue . can always come back later time.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"the-logic-behind-bayes-factors","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.3 The Logic Behind Bayes Factors","text":"demonstrate logic behind Bayes factors, play around shiny app Magnusson. Building section 1, visualisation shows Bayesian two-sample t-test, demonstrating complicated application compared beta distribution proportions. visualisation shows Bayesian estimation posterior distribution 95% Highest Density Interval (HDI) (define), Bayes factors null hypothesis centered 0. use visualisation reinforce learnt earlier extend understanding logic behind Bayes factors.visualisation, three settings:Observed effect - Expressed Cohen's d, represents standardised mean difference two groups. can set larger effects (positive negative) assume null hypothesis true (d = 0).Observed effect - Expressed Cohen's d, represents standardised mean difference two groups. can set larger effects (positive negative) assume null hypothesis true (d = 0).Sample size - can increase sample size 1 1000, steps 1 100.Sample size - can increase sample size 1 1000, steps 1 100.SD prior - prior always set 0 testing null hypothesis, can specify strong prior . Decreasing SD means confident effect 0. Increasing SD means less certain prior.SD prior - prior always set 0 testing null hypothesis, can specify strong prior . Decreasing SD means confident effect 0. Increasing SD means less certain prior.visualisation set test null hypothesis difference two groups, remember Bayes factors allow test two hypotheses. Bayes factor represented difference two dots, curves represent likelihood 0 prior posterior distributions. Bayes factor ratio two values posterior odds much belief shift favour experimental hypothesis compared null hypothesis.Play around visualisation see Bayes factor changes alter settings. Keep eye p-value 95% Confidence Interval (CI) see inferences similiar different.reinforce lessons section 1 emphasis now Bayes factors, key observations:less informative prior (higher SD), posterior dominated likelihood show posterior overwhelmed data. example, set SD 2, prior peaks 0 distribution flat accepts reasonable effect. move observed effect anywhere along scale, likelihood posterior almost completely overlap reach d = ±2.less informative prior (higher SD), posterior dominated likelihood show posterior overwhelmed data. example, set SD 2, prior peaks 0 distribution flat accepts reasonable effect. move observed effect anywhere along scale, likelihood posterior almost completely overlap reach d = ±2.stronger prior (lower SD), posterior represents compromise prior likelihood. change SD 0.5 observed effect 1, posterior closer intermediary. may observed data, prior belief null effect strong, requires data convinced otherwise.stronger prior (lower SD), posterior represents compromise prior likelihood. change SD 0.5 observed effect 1, posterior closer intermediary. may observed data, prior belief null effect strong, requires data convinced otherwise.participants / data, less uncertainty likelihood. Keeping parameters point 2, 10 participants, likelihood peaks d = 1, easily spans 0 2. increase sample size towards 1000, uncertainty around likelihood lower. data also overwhelm prior, although relatively strong prior null effect, 50 participants, likelihood posterior mostly overlap.participants / data, less uncertainty likelihood. Keeping parameters point 2, 10 participants, likelihood peaks d = 1, easily spans 0 2. increase sample size towards 1000, uncertainty around likelihood lower. data also overwhelm prior, although relatively strong prior null effect, 50 participants, likelihood posterior mostly overlap.Focusing Bayes factor supporting experimental hypothesis, effect, evidence favour experimental hypothesis increases observed effect increases increasing sample size. dissimilar frequentist statistical power, Bayesian statistics, optional stopping less problem (revise add citation). , enough data shift beliefs towards either hypothesis, can collect data update beliefs.Focusing Bayes factor supporting experimental hypothesis, effect, evidence favour experimental hypothesis increases observed effect increases increasing sample size. dissimilar frequentist statistical power, Bayesian statistics, optional stopping less problem (revise add citation). , enough data shift beliefs towards either hypothesis, can collect data update beliefs.set observed effect 0, p-value 1 suggest reject null, shift belief towards null. Bayes factors, can focus supporting null see observed effect = 0, sample size = 50, SD prior = 0.5, data 2.60 times likely null experimental hypothesis. , shift belief favour null, convincing. can obtain higher Bayes factor support null increasing sample size decreasing SD prior. last part might sound little odd first, prior strong favour null, beliefs need shift light data.set observed effect 0, p-value 1 suggest reject null, shift belief towards null. Bayes factors, can focus supporting null see observed effect = 0, sample size = 50, SD prior = 0.5, data 2.60 times likely null experimental hypothesis. , shift belief favour null, convincing. can obtain higher Bayes factor support null increasing sample size decreasing SD prior. last part might sound little odd first, prior strong favour null, beliefs need shift light data.Finally, set weak prior (SD = 2), see frequentist 95% CI Bayesian 95% HDI almost identical. weak uninformative prior, usually find values two intervals similar, interpret differently. Increasing sample size makes intervals smaller changing observed effect shifts around. make stronger prior (SD = 0.5), now 95% HDI change. frequentist 95% CI always follow likelihood based observed data. Bayesian 95% CI represents area posterior, might compromise prior likelihood, can smaller stronger prior favour null observed effect 0.Finally, set weak prior (SD = 2), see frequentist 95% CI Bayesian 95% HDI almost identical. weak uninformative prior, usually find values two intervals similar, interpret differently. Increasing sample size makes intervals smaller changing observed effect shifts around. make stronger prior (SD = 0.5), now 95% HDI change. frequentist 95% CI always follow likelihood based observed data. Bayesian 95% CI represents area posterior, might compromise prior likelihood, can smaller stronger prior favour null observed effect 0.","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"bayes-factors-for-two-independent-samples","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.4 Bayes factors for two independent samples","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"guided-example-bastian-et-al.-2014","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.4.1 Guided example (Bastian et al., 2014)","text":"first time actually used R far, need load packages data task. packages, make sure install first.guided example, reanalyse data Bastian et al. (2014). study wanted investigate whether experiencing pain together can increase levels bonding participants. study trying explain people often say friendships strengthened adversity.Participants randomly allocated two conditions: pain control. Participants pain group experienced mild pain cold pressor task (leaving hand ice cold water) wall squat (sitting wall). control group completed different task involve pain. participants completed scale measure bonded felt participants group. Higher values scale mean greater bonding.independent variable called \"CONDITION\". control group value 0 pain group value 1. wanted find whether participants pain group higher levels bonding fellow participants participants control group. little processing, dependent variable called \"mean_bonding\" mean 7 items related bonding.use Bayesian version t-test, use similar arguments frequentist version stating design formula data frame referring . study, want predict bonding rating group allocated : mean_bonding ~ CONDITION.main new argument rscale sets width prior distribution around alternative hypothesis. T-tests use Cauchy prior similar normal distribution fatter tails define one parameter: r scale. default prior set \"medium\", change depending understanding area research. See function help page different options , medium equivalent value 0.707 scaling Cauchy prior default setting statistics software. two-tailed test, means 50% distribution covers values ± 0.707. can enter numeric value precise scaling word presets like \"medium\" \"wide\" depending weak want prior .worry warning, just previous issues using tibbles BayesFactor package.medium prior, Bayes factor 1.45 (\\(BF\\)\\(_1\\)\\(_0\\) = 1.45), suggesting experimental hypothesis 1.45 times likely point null hypothesis. guidelines Wagenmakers et al. (2011) (add ref), quite weak anecdotal evidence.authors pretty convinced pain group score hire bonding rating control group, lets see happens one-tailed test see done. need define nullInterval argument state consider negative effects.Make sure check order groups check direction expect results go . expect group smaller group B, code negative effects. expect group bigger group B, code positive effects. common mistake defining wrong direction know order groups coded.one-tailed test, now two tests. row one, test want compare experimental hypothesis (negative effects) point null. row two, opposite complement experimental hypothesis. Even one-tailed test, evidence favour experimental hypothesis compared null anecdotal best (\\(BF\\)\\(_1\\)\\(_0\\) = 2.79).wanted test null compared experimental hypothesis, can simply take reciprocal object, demonstrated two-tailed object.object, already know anecdotal evidence favour experimental hypothesis, just telling us null less likely experimental hypothesis (\\(BF\\)\\(_0\\)\\(_1\\) = 0.69). come handy specifically want test null though.purposes rest demonstration, stick original object two-tailed test see can interpret inconclusive results. original study, pain group scored significantly higher control group, p-value .048, hardly convincing evidence. Bayes factors, least can see ideally need data make decision.spend time process next week, Bayes factor normally enough. also want estimate effect size precision around . Within BayesFactor package, function sample posterior distribution using MCMC sampling. need pass t-test object posterior function, include number iterations want. use 10,000 . Depending computer, may take seconds.use one-tailed test, must index first object (e.g., Bastian_ttest[1]) one-tailed test includes two lines: 1) directional alternative state null 2) complement alternative null.samples, can use generic plot function see trace plots (chapter 10) density plot posterior distributions several parameters.second fourth plots mainly interested t-test. know kind evidence different hypotheses, typically want know effect size . BayesFactor package, get mean difference groups (unhelpfully named beta) effect size Delta, kind like Cohen's d. calculated dividing t statistic square root sample size, kind standardised mean difference. One main complaints BayesFactor package explaining outputs mean explanation find old blog post, clear overview documentation.plot provides posterior distribution different statistics based sampling 10,000 times. beta, can see peak distribution around -0.5, spanning 0 -1. delta, can see peak distribution around -0.5, spans 0 -1 .fine-tuned description posterior distribution, can use handy functions bayestestR package. use much chapter 10 great plotting functions, functions work BayesFactor objects. get point estimates parameter, can use point_estimate function:best guess mean difference groups -0.49 delta -0.46 favour pain group.just want point estimate though, also want credible interval around . , hdi function., can 95% confident mean difference -1.04 0.04, delta -0.99 0.04. values cross 0, confident findings ideally need collect data.Finally, instead separate functions, handy wrapper median, 95% credible interval, ROPE (section 4).bunch tests tricks covered , check Bayesfactor package page online series vignettes.","code":"\nlibrary(BayesFactor)\nlibrary(bayestestR)\nlibrary(tidyverse)\nBastian_data <- read_csv(\"data/Bastian.csv\")\n\n# Relabel condition to be more intuitive which group is which \nBastian_data$CONDITION <- factor(Bastian_data$CONDITION, \n                                   levels = c(0, 1), \n                                   labels = c(\"Control\", \"Pain\"))\n\n# First we need to get our DV from the mean of 7 items\nbonding <- Bastian_data %>% \n  pivot_longer(cols = group101:group107, names_to = \"item\", values_to = \"score\") %>% \n  group_by(subid) %>% \n  summarise(mean_bonding = mean(score), ) %>% \n  ungroup()\n\n# add back to the main dataframe and simplify \nBastian_data <- left_join(Bastian_data, bonding, by = \"subid\") %>% \n  select(CONDITION, mean_bonding)\nBastian_ttest <- ttestBF(formula = mean_bonding ~ CONDITION,\n                        data = Bastian_data,\n                        rscale = \"medium\", \n                        paired = FALSE)## Warning: data coerced from tibble to data frame\nBastian_ttest## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 : 1.445956 ±0.01%\n## \n## Against denominator:\n##   Null, mu1-mu2 = 0 \n## ---\n## Bayes factor type: BFindepSample, JZS\nBastian_onetail <- ttestBF(formula = mean_bonding ~ CONDITION,\n                        data = Bastian_data,\n                        rscale = \"medium\", \n                        paired = FALSE,\n                        nullInterval = c(-Inf, 0)) # negative only as we expect control < pain## Warning: data coerced from tibble to data frame\nBastian_onetail## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 -Inf<d<0    : 2.790031  ±0%\n## [2] Alt., r=0.707 !(-Inf<d<0) : 0.1018811 ±0.02%\n## \n## Against denominator:\n##   Null, mu1-mu2 = 0 \n## ---\n## Bayes factor type: BFindepSample, JZS\n1 / Bastian_ttest## Bayes factor analysis\n## --------------\n## [1] Null, mu1-mu2=0 : 0.6915839 ±0.01%\n## \n## Against denominator:\n##   Alternative, r = 0.707106781186548, mu =/= 0 \n## ---\n## Bayes factor type: BFindepSample, JZS\nBastian_samples <- posterior(Bastian_ttest,\n                            iterations = 1e5) # 10,000 in math notation\nplot(Bastian_samples)\npoint_estimate(Bastian_samples)\nhdi(Bastian_samples)\ndescribe_posterior(Bastian_samples)"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"independent-activity-schroeder-epley-2015","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.4.2 Independent activity (Schroeder & Epley, 2015)","text":"independent activity, use data study Schroeder Epley (2015). aim study investigate whether delivering short speech potential employer effective landing job writing speech employer reading . Thirty-nine professional recruiters randomly assigned receive job application speech either transcript read, audio recording reading speech.recruiters rated applicants perceived intellect, impression applicant, whether recommend hiring candidate. ratings originally Likert scale ranging 0 (low intellect, impression etc.) 10 (high impression, recommendation etc.), final value representing mean across several items.example, focus hire rating (variable \"Hire_Rating\" see whether audio condition lead higher ratings transcript condition (variable \"CONDITION\")., apply learnt first guided example new independent task.","code":"\nSchroeder_data <- read_csv(\"data/Schroeder_hiring.csv\")\n\n# Relabel condition to be more intuitive which group is which \nSchroeder_data$CONDITION <- factor(Schroeder_data$CONDITION, \n                                   levels = c(0, 1), \n                                   labels = c(\"Transcript\", \"Audio\"))\nSchroeder_ttest <- NULL"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"bayes-factors-for-two-dependent-samples","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.5 Bayes factors for two dependent samples","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"guided-example-mehr-et-al.-2016","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.5.1 Guided example (Mehr et al., 2016)","text":"paired samples t-test, process identical independent samples t-test apart defining variables. , demonstrate full example like less commentary, independent data frame test understanding.next study going look Mehr et al. (2016). interested whether singing infants conveyed important information social affiliation. Infants become familiar melodies repeated specific culture. authors interested whether novel person (someone never seen ) signal child member social group attract attention singing familiar song .Mehr et al. (2016) invited 32 infants parents participate repeated measures experiment. First, parents asked repeatedly sing previously unfamiliar song infants two weeks. returned lab, measured baseline gaze (looking) infants towards two unfamiliar people screen just silently smiling . measured proportion time looking individual later sing familiar song (0.5 indicate half time spent looking familiar singer. Values closer one indicate looking longer). two silent people screen took turns sing lullaby. One people sung song infant’s parents told sing previous two weeks, one sang song lyrics rhythm, different melody. Mehr et al. (2016) repeated gaze procedure two people start experiment provide second measure gaze proportion looking familiar singer.interested whether infants increased proportion time spent looking singer sang familiar song sang, comparison sang infants. one dependent variable (gaze proportion) one within-subjects independent variable (baseline vs test). want know whether gaze proportion higher test baseline.Like Bastian et al. (2014), just anecdotal evidence favour experimental hypothesis null (\\(BF\\)\\(_1\\)\\(0\\) = 2.30).Mehr et al. (2016) expected gaze proportion higher test, try defining one-tailed test see kind evidence favour alternative hypothesis., know anecdotal evidence favour experimental hypothesis, also want effect size 95% credible interval. , can sample posterior, plot , get estimates.Just note plot fewer panels paired samples approach simplifies things. Mu mean difference first panel delta standardised effect third panel. dependent variable gaze proportion, unstandardised effect size informative standardised version.finally wrapper function median posterior distribution 95% credible interval.can see median posterior estimate mean difference -.07 95% credible interval ranging -.13 -.01. means can exclude 0 likely effects, still anecdotal evidence favour experimental hypothesis compared null.","code":"\nMehr_data <- read_csv(\"data/Mehr_voice.csv\") %>% \n  select(Baseline = Baseline_Proportion_Gaze_to_Singer, # Shorten super long names\n         Test = Test_Proportion_Gaze_to_Singer)\n\nMehr_ttest <- ttestBF(x = Mehr_data$Baseline,\n                      y = Mehr_data$Test,\n                      paired = TRUE, \n                      rscale = \"medium\")\n\nMehr_ttest## Bayes factor analysis\n## --------------\n## [1] Alt., r=0.707 : 2.296479 ±0%\n## \n## Against denominator:\n##   Null, mu = 0 \n## ---\n## Bayes factor type: BFoneSample, JZS\nMehr_samples <- posterior(Mehr_ttest,\n                          iterations = 1e5)\nplot(Mehr_samples)\ndescribe_posterior(Mehr_samples)"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"independent-activity-zwaan-et-al.-2020","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.5.2 Independent activity (Zwaan et al., 2020)","text":"final independent activity, data Zwaan et al. (2020) wanted replicate experiments cognitive psychology see replicable . exercise, explore flanker task.short, two conditions: congruent incongruent. congruent trials, five symbols like arrows participants must identify central symbol keyboard response. incongruent trials, four outer symbols different central symbol. Typically, find participants respond faster congruent trials incongruent trials. dependent variable mean response time milliseconds (ms).want know whether response times faster congruent trials (session1_responsecongruent) incongruent trials (session1_incongruent). Zwaan et al. measured things like changing stimuli repeated task two sessions, just focus first session example. scenario, might want think one-tailed test since strong prediction expect faster responses congruent condition.","code":"\nZwaan_data <- read_csv(\"data/Zwaan_flanker.csv\")\n\nZwaan_ttest <- NULL"},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"equivalence-testing-vs-rope","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.6 Equivalence Testing vs ROPE","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"guided-example-for-two-independent-samples","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.6.1 Guided example for two independent samples","text":"","code":""},{"path":"introduction-to-bayesian-hypothesis-testing.html","id":"independent-activity","chapter":"9 Introduction to Bayesian Hypothesis Testing","heading":"9.6.2 Independent activity","text":"","code":""},{"path":"introduction-to-bayesian-estimation.html","id":"introduction-to-bayesian-estimation","chapter":"10 Introduction to Bayesian Estimation","heading":"10 Introduction to Bayesian Estimation","text":"","code":""},{"path":"installing-r.html","id":"installing-r","chapter":"A Installing R","heading":"A Installing R","text":"Installing R RStudio usually straightforward. sections explain helpful YouTube video .","code":""},{"path":"installing-r.html","id":"installing-base-r","chapter":"A Installing R","heading":"A.1 Installing Base R","text":"Install base R. Choose download link operating system (Linux, Mac OS X, Windows).Mac, install latest release newest R-x.x.x.pkg link (legacy version older operating system). install R, also install XQuartz able use visualisation packages.installing Windows version, choose \"base\" subdirectory click download link top page. install R, also install RTools; use \"recommended\" version highlighted near top list.using Linux, choose specific operating system follow installation instructions.","code":""},{"path":"installing-r.html","id":"installing-rstudio","chapter":"A Installing R","heading":"A.2 Installing RStudio","text":"Go rstudio.com download RStudio Desktop (Open Source License) version operating system list titled Installers Supported Platforms.","code":""},{"path":"installing-r.html","id":"rstudio-settings","chapter":"A Installing R","heading":"A.3 RStudio Settings","text":"settings fix immediately updating RStudio. Go Global Options... Tools menu (⌘,), General tab, uncheck box says Restore .RData workspace startup. keep things around workspace, things get messy, unexpected things happen. always start clear workspace. also means never want save workspace exit, set Never. thing want save scripts.may also want change appearance code. Different fonts themes can sometimes help visual difficulties dyslexia.\nFigure .1: RStudio General Appearance settings\nmay also want change settings Code tab. Foe example, Lisa prefers two spaces instead tabs code likes able see whitespace characters. matter personal preference.\nFigure .2: RStudio Code settings\n","code":""},{"path":"installing-r.html","id":"installing-latex","chapter":"A Installing R","heading":"A.4 Installing LaTeX","text":"can install LaTeX typesetting system produce PDF reports RStudio. Without additional installation, able produce reports HTML PDF. course require make PDFs. generate PDF reports, additionally need install tinytex (Xie, 2022) run following code:","code":"\ntinytex::install_tinytex()"},{"path":"symbols.html","id":"symbols","chapter":"B Symbols","heading":"B Symbols","text":"\nFigure B.1: Image James Chapman/Soundimals\n","code":""},{"path":"conventions.html","id":"conventions","chapter":"C Conventions","heading":"C Conventions","text":"book use following conventions:Generic code: list(number = 1, letter = \"\")Highlighted code: dplyr::slice_max()File paths: data/sales.csvR Packages: tidyverseBacktick functions: paste()Functions: paste()Strings: \"psyTeachR\"Numbers: 100, 3.14Logical values: TRUE, FALSEGlossary items: ordinalCitations: Wickham (2021)Internal links: Chapter ??External links: R Data ScienceMenu/interface options: New File...","code":""},{"path":"conventions.html","id":"webexercises","chapter":"C Conventions","heading":"C.1 Webexercises","text":"See webexercises details use materials.Type integer: going learn lot: TRUEFALSEWhat p-value?\n\nprobability null hypothesis truethe probability observed (extreme) data, assumption null-hypothesis truethe probability making error conclusion\nfound hidden text!","code":"\nprint(\"You found some hidden code!\")## [1] \"You found some hidden code!\""},{"path":"conventions.html","id":"alert-boxes","chapter":"C Conventions","heading":"C.2 Alert boxes","text":"Informational asides.Notes warn something.Notes things cause serious errors.Try .","code":""},{"path":"conventions.html","id":"code-chunks","chapter":"C Conventions","heading":"C.3 Code Chunks","text":"","code":"\n# code chunks\npaste(\"Applied\", \"Data\", \"Skills\", 1, sep = \" \")## [1] \"Applied Data Skills 1\"```{r setup, message = FALSE}\n# code chunks with visible r headers\nlibrary(tidyverse)```"},{"path":"conventions.html","id":"glossary","chapter":"C Conventions","heading":"C.4 Glossary","text":"","code":""},{"path":"glossary-1.html","id":"glossary-1","chapter":"D Glossary","heading":"D Glossary","text":"can use glossary() function automatically link term psyTeachR glossary make project-specific glossary.create link glossary include tooltip short definition hover term. Use following syntax inline r: glossary(\"word\"). example, common data types integer, double, character.need link definition, using different form word, add display version second argument (display). can also override automatic short definition providing third argument (def). Add argument link = FALSE just want hover definition link psyTeachR glossary.[1] \"Data Types\"can add glossary table end chapter following code. creates table terms used chapter previous glossary_table() function. uses kableExtra(), use code chunk, set results='asis'.want contribute glossary, fork github project, add terms submit pull request, suggest new term issues page.","code":"\nglossary(\"data type\", \n         display = \"Data Types\", \n         def = \"My custom definition of data types\", \n         link = FALSE)```{r, echo=FALSE, results='asis'}\nglossary_table()```"},{"path":"license.html","id":"license","chapter":"License","heading":"License","text":"book licensed Creative Commons Attribution-ShareAlike 4.0 International License (CC--SA 4.0). free share adapt book. must give appropriate credit (DeBruine, 2021), provide link license, indicate changes made. adapt material, must distribute contributions license original.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
